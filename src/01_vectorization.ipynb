{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vetorizar documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessário para a NLTK\n",
    "nltk.download('stopwords')  # Baixa a lista de stop words (palavras comuns) para uso no processamento de texto\n",
    "nltk.download('punkt')  # Baixa o tokenizer Punkt, necessário para a tokenização de frases\n",
    "\n",
    "# Carregar o modelo de português para o spaCy\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(text):\n",
    "\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Converte para minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove pontuação\n",
    "    # []: colchetes são usados para definir uma classe de caracteres.\n",
    "    # ^: quando usado no início de uma classe de caracteres, o ^ nega a classe, ou seja, seleciona tudo que não está na classe.\n",
    "    # \\w: corresponde a qualquer caractere alfanumérico (letras e números, incluindo o caractere de sublinhado _)\n",
    "    # \\s: corresponde a qualquer espaço em branco (espaços, tabulações, quebras de linha).\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove underlines\n",
    "    text = re.sub(r'_+', '', text)\n",
    "\n",
    "    # Remove números\n",
    "    # \\d: corresponde a qualquer dígito (de 0 a 9).\n",
    "    # +: significa “um ou mais” do elemento precedente. Portanto, \\d+ corresponde a uma sequência de um ou mais dígitos consecutivos.\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    # Obtém a lista de stopwords em português usando o NLTK e as converte para um conjunto para melhorar a eficiência da busca\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "    # Divide o texto em palavras, remove as stopwords e então junta as palavras restantes de volta em uma string\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df.resultado != 'NÃO DEFINIDO']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['detalhamento'] = data['detalhamento'].apply(remove_noise)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1]['detalhamento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['detalhamento'] = data['detalhamento'].apply(remove_stopwords)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data['detalhamento'][267]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "data['tokens'] = data['detalhamento'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'][267]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming e Lemmatização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_stemming(tokens):\n",
    "#     stemmer = PorterStemmer()\n",
    "#     stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "#     return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['stemming'] = data['tokens'].apply(apply_stemming)\n",
    "# data['stemming'][267]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer = PorterStemmer()\n",
    "\n",
    "# # Tokeniza a frase em palavras\n",
    "# palavras = word_tokenize(data['detalhamento'][267])\n",
    "\n",
    "# # Aplica o stemming a cada palavra\n",
    "# stemmed_words = [stemmer.stem(word) for word in palavras]\n",
    "\n",
    "# print(\"Frase original:\", data['detalhamento'][267])\n",
    "# print(\"Palavras após Stemming:\", stemmed_words)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lemming(doc):\n",
    "    doc = ' '.join(doc)\n",
    "\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "    doc = nlp(doc)\n",
    "\n",
    "    lemmatized_words = [token.lemma_ for token in doc]\n",
    "\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_version'] = data['tokens'].apply(apply_lemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['clean_version']\n",
    "y = data['resultado']\n",
    "\n",
    "print(len(x),  len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "print(len(x_train), len(y_train))\n",
    "print(len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "x_train_flattened = [item for sublist in x_train for item in sublist]\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect.fit(x_train_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dtm = vect.transform(x_train_flattened)\n",
    "\n",
    "x_test_flattened = [item for sublist in x_test for item in sublist]\n",
    "\n",
    "x_test_dtm = vect.transform(x_test_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "\n",
    "tfidf_transformer.fit(x_train_dtm)\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "\n",
    "x_train_tfidf_dense = x_train_tfidf.toarray()\n",
    "\n",
    "print(x_train_tfidf_dense)\n",
    "\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer_tfidf.fit_transform(x_train_flattened)\n",
    "\n",
    "print(tfidf_matrix.toarray())\n",
    "print(vectorizer_tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "# Ajustar e transformar os documentos em uma matriz TF-IDF\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(\n",
    "    data['clean_version'].apply(lambda x: ' '.join(x)))\n",
    "vocab = vectorizer_tfidf.get_feature_names_out()\n",
    "print(\"Representação TF-IDF:\\n\", X_tfidf.toarray())\n",
    "print(\"Vocabulário TF-IDF:\\n\", vocab)\n",
    "\n",
    "print(\"Vocabulário TF-IDF:\", vocab)\n",
    "# Imprime a matriz TF-IDF com rótulos de linha e coluna\n",
    "print(\"Matriz TF-IDF:\")\n",
    "print(\"Documento \", end=\"\")\n",
    "for i, doc in enumerate(X_tfidf.toarray()):\n",
    "    print(f\"Documento {i+1}:\", end=\"   \")\n",
    "    for word, tfidf in zip(vocab, X_tfidf[i].toarray()[0]):\n",
    "        if tfidf == 0:\n",
    "            continue\n",
    "        print(f\"{word}: {tfidf:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorizar dataframe using TFiDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['detalhamento'] = data['clean_version'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf = data.drop(columns=[\n",
    "                       'requerente_8', 'lemming', 'stemming', 'tokens', 'pdf_file_path', 'resultado'])\n",
    "columns = data_tfidf.columns\n",
    "\n",
    "for column in columns:\n",
    "    print(f'== {column} ==')\n",
    "    if data_tfidf[column].str.strip().any():\n",
    "        tfidf_matrix = vectorizer_tfidf.fit_transform(data_tfidf[column])\n",
    "\n",
    "        data_tfidf[column] = tfidf_matrix.toarray().mean(axis=1)\n",
    "    else:\n",
    "        data_tfidf[column] = df[column].replace('', 0)\n",
    "\n",
    "data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = data['resultado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.replace('DEFERIDO', 1)\n",
    "labels = labels.replace('INDEFERIDO', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data_tfidf, labels, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervied Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to develop and evaluate machine learning models to assess performance and conduct a comparative analysis of the results. We have selected Logistic Regression and Random Forest as the primary models for this study, allowing us to draw informed conclusions based on their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Logistic Regression?\n",
    "\n",
    "Simplicity and Interpretability: Logistic Regression is a straightforward and interpretable model. It provides probabilities that can be easily understood and translated into decision-making. The coefficients of the model indicate the influence of each feature on the outcome, making it easier to interpret and understand the relationship between the variables.\n",
    "\n",
    "Linear Decision Boundary: Logistic Regression assumes a linear relationship between the features and the outcome. This can be beneficial when the true relationship is approximately linear, allowing for efficient and effective modeling. It provides a clear decision boundary that separates classes based on a linear combination of the input features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming categorical variables into dummies\n",
    "X = pd.get_dummies(df.drop(columns=['resultado']), drop_first=True)\n",
    "y = df['resultado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the target variable into numerical values\n",
    "y = df['resultado'].map({'DEFERIDO': 1, 'INDEFERIDO': 0, 'NÃO DEFINIDO': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset, training and making previsions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Logistic Regression model for multiclass classification\n",
    "model = LogisticRegression(multi_class='ovr')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_logistic = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating\n",
    "accuracy = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f'Acuracy: {accuracy:.2f}')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_logistic)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "class_report = classification_report(y_test, y_pred_logistic)\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Random Forest?\n",
    "\n",
    "Non-Linearity: Unlike Logistic Regression, which assumes a linear relationship between the variables and the outcome, Random Forest can capture more complex interactions.\n",
    "\n",
    "Immune to Overfitting: Since it is an ensemble of multiple trees, it tends to be more resistant to overfitting.\n",
    "\n",
    "Interpretability: You can obtain the feature importance, which helps to understand which features have the most impact on the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the categorical variables have already been transformed\n",
    "X = pd.get_dummies(df.drop(columns=['resultado']), drop_first=True)\n",
    "y = df['resultado'].map({'DEFERIDO': 1, 'INDEFERIDO': 0, 'NÃO DEFINIDO': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Creating and training the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Acuracy: {accuracy:.2f}')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "class_report = classification_report(y_test, y_pred_rf)\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the predicted probabilities\n",
    "y_prob_lr = model.predict_proba(X_test)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "# ROC Curves\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr[:, 1], pos_label=1)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf[:, 1], pos_label=1)\n",
    "\n",
    "# AUC (Area Under the Curve)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# Plotting the ROC Curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_lr, tpr_lr, color='blue',\n",
    "         label=f'Logistic Regression (AUC = {roc_auc_lr:.2f})')\n",
    "plt.plot(fpr_rf, tpr_rf, color='green',\n",
    "         label=f'Random Forest (AUC = {roc_auc_rf:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Supondo que você já tenha os valores reais e as previsões dos modelos\n",
    "# y_true = valores reais\n",
    "# y_pred_logistic = previsões do modelo de Regressão Logística\n",
    "# y_pred_rf = previsões do modelo de Random Forest\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['INDEFERIDO', 'DEFERIDO', 'NÃO DEFINIDO'],\n",
    "                yticklabels=['INDEFERIDO', 'DEFERIDO', 'NÃO DEFINIDO'])\n",
    "    # plt.title(f'Matriz de Confusão - {model_name}', fontsize=14)\n",
    "    plt.ylabel('Valores Reais', fontsize=12)\n",
    "    plt.xlabel('Valores Previstos', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Exemplo de uso com Regressão Logística\n",
    "plot_confusion_matrix(y_test, y_pred_logistic, \"Regressão Logística\")\n",
    "\n",
    "# Exemplo de uso com Random Forest\n",
    "plot_confusion_matrix(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado não supervisionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### De Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_df(df, num_features):\n",
    "\n",
    "    correlation_matrix = df.corr()\n",
    "\n",
    "    average_correlation = correlation_matrix.abs().mean().sort_values()\n",
    "\n",
    "    smallest_average_correlations = average_correlation.head(\n",
    "        num_features).index.tolist()\n",
    "\n",
    "    return df[smallest_average_correlations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_df(df, num_components):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    return pd.DataFrame(pca.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nn_accuracy(df, labels):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df, labels, test_size=0.3, random_state=42)\n",
    "    knn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_representation(df1, df2, labels):\n",
    "    accuracy1 = get_k_nn_accuracy(df1, labels)\n",
    "    accuracy2 = get_k_nn_accuracy(df2, labels)\n",
    "\n",
    "    print(f'1: {accuracy1} x 2: {accuracy2}')\n",
    "\n",
    "    return df1 if accuracy1 > accuracy2 else df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf = data_tfidf.drop(['advogado_2', 'requerente_3', 'requerente_4',\n",
    "                              'requerente_5', 'requerente_6', 'requerente_7',\n",
    "                              'impugnado_2', 'impugnado', 'fiscal_de_lei_nome',\n",
    "                              'formal_request', 'free_judicial', 'judicial_secrecy', 'id'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1 = get_k_nn_accuracy(data_tfidf, labels)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecionando de atributos pela correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset_corr_3 = get_correlation_df(data_tfidf, 3)\n",
    "reduced_dataset_corr_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset_corr_9 = get_correlation_df(data_tfidf, 9)\n",
    "reduced_dataset_corr_9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df_corr = get_best_representation(\n",
    "    reduced_dataset_corr_3, reduced_dataset_corr_9, labels)\n",
    "selected_df_corr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Redução de dimensionalidade pelo PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca_90_cov = get_pca_df(data_tfidf, 0.9)\n",
    "dataset_pca_90_cov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca_3_cps = get_pca_df(data_tfidf, 3)\n",
    "dataset_pca_3_cps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df_pca = get_best_representation(\n",
    "    dataset_pca_90_cov, dataset_pca_3_cps, labels)\n",
    "selected_df_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_values(df, labels, model_labels):\n",
    "    from sklearn.metrics import davies_bouldin_score, silhouette_score, adjusted_rand_score\n",
    "\n",
    "    indice_db = davies_bouldin_score(df, model_labels)\n",
    "    indice_sil = silhouette_score(df, model_labels, metric='euclidean')\n",
    "    indice_cr = adjusted_rand_score(labels, model_labels)\n",
    "\n",
    "    return indice_db, indice_sil, indice_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_labels(df, num_clusters):\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    km = KMeans(n_clusters=num_clusters, init='k-means++',\n",
    "                max_iter=300, n_init=10, random_state=42)\n",
    "\n",
    "    km.fit(df)\n",
    "\n",
    "    return km.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hierarquico_labels(df, num_clusters, linkage):\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "    hiera_aglo = AgglomerativeClustering(\n",
    "        n_clusters=num_clusters, metric='euclidean', linkage=linkage)\n",
    "\n",
    "    hiera_aglo.fit(df)\n",
    "\n",
    "    return hiera_aglo.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_em_labels(df, num_components, cov_type):\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    from sklearn.metrics import davies_bouldin_score, silhouette_score, adjusted_rand_score\n",
    "\n",
    "    gmm = GaussianMixture(n_components=num_components,\n",
    "                          covariance_type=cov_type)\n",
    "\n",
    "    gmm.fit(df)\n",
    "\n",
    "    return gmm.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbscan_labels(df, eps_value, minimum_samples):\n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    dbscan = DBSCAN(eps=eps_value, min_samples=minimum_samples)\n",
    "\n",
    "    dbscan.fit(df)\n",
    "\n",
    "    return dbscan.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_labels(df, **kwargs):\n",
    "    import pandas as pd\n",
    "\n",
    "    labels_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        km_labels = get_kmeans_labels(df, index)\n",
    "        gmm_labels = get_hierarquico_labels(df, index, kwargs.get('linkage'))\n",
    "        em_labels = get_em_labels(df, index, kwargs.get('cov_type'))\n",
    "        dbscan_labels = get_dbscan_labels(df, kwargs.get('eps_value'), index)\n",
    "\n",
    "        labels_values = {'Grupos': index, 'Kmeans': km_labels,\n",
    "                         'Hierarquico': gmm_labels, 'EM': em_labels, 'DBSCAN': dbscan_labels}\n",
    "\n",
    "        labels_data.append(labels_values)\n",
    "\n",
    "    df_labels = pd.DataFrame(labels_data)\n",
    "    df_labels.index = df_labels.index + 2\n",
    "\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_indices(df, labels, models_labels, is_corr):\n",
    "    import pandas as pd\n",
    "\n",
    "    indices_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        db_value_km, sil_value_km, cr_value_km = get_indices_values(\n",
    "            df, labels, models_labels.loc[index, 'Kmeans'])\n",
    "        db_value_hiera, sil_value_hiera, cr_value_hiera = get_indices_values(\n",
    "            df, labels, models_labels.loc[index, 'Hierarquico'])\n",
    "        db_value_em, sil_value_em, cr_value_em = get_indices_values(\n",
    "            df, labels, models_labels.loc[index, 'EM'])\n",
    "        if not is_corr:\n",
    "            db_value_dbscan, sil_value_dbscan, cr_value_dbscan = get_indices_values(\n",
    "                df, labels, models_labels.loc[index, 'DBSCAN'])\n",
    "\n",
    "        indices_values = {\n",
    "            'Grupos': index,\n",
    "            'Kmeans': {'DB': db_value_km, 'SIL': sil_value_km, 'CR': cr_value_km},\n",
    "            'Hierarquico': {'DB': db_value_hiera, 'SIL': sil_value_hiera, 'CR': cr_value_hiera},\n",
    "            'EM': {'DB': db_value_em, 'SIL': sil_value_em, 'CR': cr_value_em},\n",
    "        }\n",
    "\n",
    "        if not is_corr:\n",
    "            indices_values.update(\n",
    "                {'DBSCAN': {'DB': db_value_dbscan, 'SIL': sil_value_dbscan, 'CR': cr_value_dbscan}})\n",
    "\n",
    "        indices_data.append(indices_values)\n",
    "\n",
    "    df_indices = pd.DataFrame(indices_data)\n",
    "    df_indices.index = df_indices.index + 2\n",
    "\n",
    "    return df_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_indices(df_orig, df_corr, df_pca, cluster_type):\n",
    "    import pandas as pd\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    indices_list = ['DB', 'SIL', 'CR']\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=3, subplot_titles=(\n",
    "        'Índice - Davies-Bouldin', 'Índice - Silhouette', 'Índice - Adjusted Rand Score'))\n",
    "\n",
    "    for index, indice in enumerate(indices_list, 1):\n",
    "        fig.add_trace(go.Scatter(x=df_orig['Grupos'], y=df_orig[cluster_type].apply(\n",
    "            lambda x: x[indice]), name='Base original'), row=1, col=index)\n",
    "        if cluster_type != 'DBSCAN':\n",
    "            fig.add_trace(go.Scatter(x=df_corr['Grupos'], y=df_corr[cluster_type].apply(\n",
    "                lambda x: x[indice]), name='Correlação'), row=1, col=index)\n",
    "        fig.add_trace(go.Scatter(x=df_pca['Grupos'], y=df_pca[cluster_type].apply(\n",
    "            lambda x: x[indice]), name='PCA'), row=1, col=index)\n",
    "\n",
    "    fig.update_layout(title=f'Gráfico de {\n",
    "                      cluster_type.upper()}', showlegend=True, boxmode='group')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geração de gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_models_labels = get_models_labels(\n",
    "    data_tfidf, linkage='ward', cov_type='full', eps_value=.1)\n",
    "pca_models_labels = get_models_labels(\n",
    "    selected_df_pca, linkage='ward', cov_type='full', eps_value=.1)\n",
    "corr_models_labels = get_models_labels(\n",
    "    selected_df_corr, linkage='ward', cov_type='full', eps_value=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cluster_indices = get_cluster_indices(\n",
    "    data_tfidf, labels, original_models_labels, False)\n",
    "pca_cluster_indices = get_cluster_indices(\n",
    "    selected_df_pca, labels, pca_models_labels, False)\n",
    "corr_cluster_indices = get_cluster_indices(\n",
    "    selected_df_corr, labels, corr_models_labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade jupyter notebook jupyterlab plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices,\n",
    "                     corr_cluster_indices, pca_cluster_indices, 'Kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices,\n",
    "                     corr_cluster_indices, pca_cluster_indices, 'Hierarquico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices,\n",
    "                     corr_cluster_indices, pca_cluster_indices, 'EM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices,\n",
    "                     corr_cluster_indices, pca_cluster_indices, 'DBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comitê de Agrupamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_binary_matrix(clabels):\n",
    "    from scipy import sparse\n",
    "\n",
    "    data_len = len(clabels)\n",
    "\n",
    "    matrix = np.zeros((data_len, data_len))\n",
    "\n",
    "    for index in range(data_len):\n",
    "        matrix[index, :] = clabels == clabels[index]\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(models_labels):\n",
    "    n_runs, n_data = models_labels.shape[0], models_labels.shape[1]\n",
    "\n",
    "    sim_matrix = np.zeros((n_data, n_data))\n",
    "\n",
    "    for index in range(n_runs):\n",
    "        sim_matrix += build_binary_matrix(models_labels[index, :])\n",
    "\n",
    "    sim_matrix = sim_matrix / n_runs\n",
    "\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_indices(df, final_labels, labels):\n",
    "    from sklearn.metrics import davies_bouldin_score, silhouette_score, adjusted_rand_score\n",
    "\n",
    "    indice_db = davies_bouldin_score(df, final_labels)\n",
    "    indice_sil = silhouette_score(df, final_labels, metric='euclidean')\n",
    "    indice_cr = adjusted_rand_score(labels, final_labels)\n",
    "\n",
    "    return indice_db, indice_sil, indice_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_labels_en(df: pd.DataFrame, num_clusters):\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    km_model = KMeans(n_clusters=num_clusters, n_init=4, random_state=214)\n",
    "    km_model.fit(df)\n",
    "\n",
    "    return km_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hierarquico_labels_en(df: pd.DataFrame, num_clusters):\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "    agglo_model = AgglomerativeClustering(n_clusters=num_clusters)\n",
    "    agglo_model.fit(df)\n",
    "\n",
    "    return agglo_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_em_labels_en(df: pd.DataFrame, num_components):\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "\n",
    "    gmm_model = GaussianMixture(n_components=num_components, random_state=214)\n",
    "\n",
    "    gmm_model.fit(df)\n",
    "    labels = gmm_model.predict(df)\n",
    "\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbscan_labels_en(df, eps, min_samples):\n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    dbscan_models = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "\n",
    "    dbscan_models.fit(df)\n",
    "\n",
    "    return dbscan_models.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_matrix_en(models_labels: np.ndarray):\n",
    "\n",
    "    return build_similarity_matrix(models_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_labels_en(sim_matrix, num_clusters):\n",
    "    from sklearn.cluster import SpectralClustering\n",
    "\n",
    "    spec_clt = SpectralClustering(n_clusters=num_clusters, affinity='precomputed',\n",
    "                                  n_init=5, random_state=214)\n",
    "\n",
    "    final_labels = spec_clt.fit_predict(sim_matrix)\n",
    "\n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_df(df: pd.DataFrame, labels: np.ndarray, **kwargs) -> pd.DataFrame:\n",
    "    import pandas as pd\n",
    "\n",
    "    indices_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        db_df, sil_df, cr_df = {}, {}, {}\n",
    "\n",
    "        kmeans_labels = get_kmeans_labels_en(df, index)\n",
    "        hierarquico_labels = get_hierarquico_labels_en(df, index)\n",
    "        em_labels = get_em_labels_en(df, index)\n",
    "        dbscan_labels = get_dbscan_labels_en(df, .1, index)\n",
    "\n",
    "        models_labels = np.array(\n",
    "            [kmeans_labels, hierarquico_labels, em_labels, dbscan_labels])\n",
    "\n",
    "        sim_matrix = get_similarity_matrix_en(models_labels)\n",
    "\n",
    "        final_labels = get_final_labels_en(sim_matrix, index)\n",
    "\n",
    "        db_value, sil_value, cr_value = get_ensemble_indices(\n",
    "            df, final_labels, labels)\n",
    "\n",
    "        indice_values = {'Grupos': index, 'DB': db_value,\n",
    "                         'Silhouette': sil_value, 'CR': cr_value, 'Labels': final_labels}\n",
    "        indices_data.append(indice_values)\n",
    "\n",
    "    indices_ensemble_df = pd.DataFrame(indices_data)\n",
    "    indices_ensemble_df.index = indices_ensemble_df.index + 2\n",
    "\n",
    "    return indices_ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ensemble_indices(en_df_original: pd.DataFrame, en_df_corr: pd.DataFrame, en_df_pca: pd.DataFrame, indice_name: str) -> None:\n",
    "    import pandas as pd\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    indice_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        indice_values = {'Grupos': index + 2,\n",
    "                         'Original': en_df_original.loc[index, indice_name],\n",
    "                         'Correlação': en_df_corr.loc[index, indice_name],\n",
    "                         'PCA': en_df_pca.loc[index, indice_name]\n",
    "                         }\n",
    "        indice_data.append(indice_values)\n",
    "\n",
    "    df = pd.DataFrame(indice_data)\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1, subplot_titles=(\n",
    "        f'Índice - {indice_name}'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['Grupos'], y=df['Original'], name='Base original'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['Grupos'], y=df['Correlação'], name='Correlação'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df['Grupos'],\n",
    "                  y=df['PCA'], name='PCA'), row=1, col=1)\n",
    "\n",
    "    fig.update_layout(title=f'Gráfico de comitê de agrupamento - Índice {\n",
    "                      indice_name}', showlegend=True, boxmode='group')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_df_original = get_ensemble_df(data_tfidf, labels)\n",
    "ensemble_df_corr = get_ensemble_df(selected_df_corr, labels)\n",
    "ensemble_df_pca = get_ensemble_df(selected_df_pca, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble_indices(ensemble_df_original,\n",
    "                      ensemble_df_corr, ensemble_df_pca, 'DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble_indices(ensemble_df_original, ensemble_df_corr,\n",
    "                      ensemble_df_pca, 'Silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble_indices(ensemble_df_original,\n",
    "                      ensemble_df_corr, ensemble_df_pca, 'CR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste Estatístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cr_df() -> pd.DataFrame:\n",
    "    cr_data = pd.DataFrame(columns=[\n",
    "        'kmeans', 'hierarquico', 'em', 'dbscan', 'ensemble'\n",
    "    ], index=range(2, 21))\n",
    "\n",
    "    return cr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cr_values(df, ensemble_df):\n",
    "    result_df = get_cr_df()\n",
    "\n",
    "    km_cr_values = df['Kmeans'].apply(lambda x: x['CR'])\n",
    "    ag_cr_values = df['Hierarquico'].apply(lambda x: x['CR'])\n",
    "    em_cr_values = df['EM'].apply(lambda x: x['CR'])\n",
    "    dbscan_cr_values = df['DBSCAN'].apply(lambda x: x['CR'])\n",
    "\n",
    "    for num_cluster in range(2, 21):\n",
    "        result_df.loc[num_cluster] = [\n",
    "            km_cr_values.loc[num_cluster],\n",
    "            ag_cr_values.loc[num_cluster],\n",
    "            em_cr_values.loc[num_cluster],\n",
    "            dbscan_cr_values.loc[num_cluster],\n",
    "            ensemble_df.loc[num_cluster, 'CR']\n",
    "        ]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cr_values_corr(df, ensemble_df):\n",
    "    result_df = get_cr_df()\n",
    "    result_df = result_df.drop('dbscan', axis=1)\n",
    "\n",
    "    km_cr_values = df['Kmeans'].apply(lambda x: x['CR'])\n",
    "    ag_cr_values = df['Hierarquico'].apply(lambda x: x['CR'])\n",
    "    em_cr_values = df['EM'].apply(lambda x: x['CR'])\n",
    "\n",
    "    for num_cluster in range(2, 21):\n",
    "        result_df.loc[num_cluster] = [\n",
    "            km_cr_values.loc[num_cluster],\n",
    "            ag_cr_values.loc[num_cluster],\n",
    "            em_cr_values.loc[num_cluster],\n",
    "            ensemble_df.loc[num_cluster, 'CR']\n",
    "        ]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_friedman_result(df):\n",
    "    from scipy.stats import friedmanchisquare\n",
    "\n",
    "    friedman_chi2, friedman_p_value = friedmanchisquare(\n",
    "        *[df[col] for col in df.columns])\n",
    "    print(\"Teste de Friedman\")\n",
    "    print(f\"p-valor: {friedman_p_value:.4f}\")\n",
    "    print(f\"qui-quadrado: {friedman_chi2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nemenyi_result(df):\n",
    "    from scikit_posthocs import posthoc_nemenyi_friedman\n",
    "\n",
    "    nemenyi_results = posthoc_nemenyi_friedman(df)\n",
    "    print(\"Teste Nemenyi (pós-hoc):\")\n",
    "    print(nemenyi_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nemenyi_result(df, title):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scikit_posthocs import posthoc_nemenyi_friedman\n",
    "\n",
    "    nemenyi_results = posthoc_nemenyi_friedman(df)\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.heatmap(nemenyi_results, annot=True, cmap='coolwarm', fmt=\".4f\", cbar=True,\n",
    "                linewidths=0.5, linecolor='black', vmin=0, vmax=1)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_original = fill_cr_values(original_cluster_indices, ensemble_df_original)\n",
    "cr_pca = fill_cr_values(pca_cluster_indices, ensemble_df_pca)\n",
    "cr_corr = fill_cr_values_corr(corr_cluster_indices, ensemble_df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original\")\n",
    "print_friedman_result(cr_original)\n",
    "print(\"Corr\")\n",
    "print_friedman_result(cr_corr)\n",
    "print(\"PCA\")\n",
    "print_friedman_result(cr_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original\")\n",
    "print_nemenyi_result(cr_original)\n",
    "print(\"Corr\")\n",
    "print_nemenyi_result(cr_corr)\n",
    "print(\"PCA\")\n",
    "print_nemenyi_result(cr_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nemenyi_result(cr_original, \"Teste Nemenyi (pós-hoc) - Original\")\n",
    "plot_nemenyi_result(cr_corr, \"Teste Nemenyi (pós-hoc) - Correlação\")\n",
    "plot_nemenyi_result(cr_pca, \"Teste Nemenyi (pós-hoc) - PCA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
