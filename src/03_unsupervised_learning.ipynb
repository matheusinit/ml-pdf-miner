{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado não supervisionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_tfidf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['resultado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.replace('DEFERIDO', 1)\n",
    "labels = labels.replace('INDEFERIDO', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções de Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_df(df, num_features):\n",
    "\n",
    "    correlation_matrix = df.corr()\n",
    "\n",
    "    average_correlation = correlation_matrix.abs().mean().sort_values()\n",
    "\n",
    "    smallest_average_correlations = average_correlation.head(\n",
    "        num_features).index.tolist()\n",
    "\n",
    "    return df[smallest_average_correlations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_df(df, num_components):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    return pd.DataFrame(pca.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nn_accuracy(df, labels):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df, labels, test_size=0.3, random_state=42)\n",
    "    knn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_representation(df1, df2, labels):\n",
    "    accuracy1 = get_k_nn_accuracy(df1, labels)\n",
    "    accuracy2 = get_k_nn_accuracy(df2, labels)\n",
    "\n",
    "    print(f'1: {accuracy1} x 2: {accuracy2}')\n",
    "\n",
    "    return df1 if accuracy1 > accuracy2 else df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf = data_tfidf.drop(['advogado_2', 'requerente_3', 'requerente_4',\n",
    "                              'requerente_5', 'requerente_6', 'requerente_7',\n",
    "                              'impugnado_2', 'impugnado', 'fiscal_de_lei_nome',\n",
    "                              'formal_request', 'free_judicial', 'judicial_secrecy', 'id'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1 = get_k_nn_accuracy(data_tfidf, labels)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecionando de atributos pela correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset_corr_3 = get_correlation_df(data_tfidf, 3)\n",
    "reduced_dataset_corr_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset_corr_9 = get_correlation_df(data_tfidf, 9)\n",
    "reduced_dataset_corr_9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df_corr = get_best_representation(\n",
    "    reduced_dataset_corr_3, reduced_dataset_corr_9, labels)\n",
    "selected_df_corr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Redução de dimensionalidade pelo PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca_90_cov = get_pca_df(data_tfidf, 0.9)\n",
    "dataset_pca_90_cov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca_3_cps = get_pca_df(data_tfidf, 3)\n",
    "dataset_pca_3_cps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df_pca = get_best_representation(\n",
    "    dataset_pca_90_cov, dataset_pca_3_cps, labels)\n",
    "selected_df_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_values(df, labels, model_labels):\n",
    "    from sklearn.metrics import davies_bouldin_score, silhouette_score, adjusted_rand_score\n",
    "\n",
    "    indice_db = davies_bouldin_score(df, model_labels)\n",
    "    indice_sil = silhouette_score(df, model_labels, metric='euclidean')\n",
    "    indice_cr = adjusted_rand_score(labels, model_labels)\n",
    "\n",
    "    return indice_db, indice_sil, indice_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_labels(df, num_clusters):\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    km = KMeans(n_clusters=num_clusters, init='k-means++',\n",
    "                max_iter=300, n_init=10, random_state=42)\n",
    "\n",
    "    km.fit(df)\n",
    "\n",
    "    return km.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hierarquico_labels(df, num_clusters, linkage):\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "    hiera_aglo = AgglomerativeClustering(\n",
    "        n_clusters=num_clusters, metric='euclidean', linkage=linkage)\n",
    "\n",
    "    hiera_aglo.fit(df)\n",
    "\n",
    "    return hiera_aglo.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_em_labels(df, num_components, cov_type):\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    from sklearn.metrics import davies_bouldin_score, silhouette_score, adjusted_rand_score\n",
    "\n",
    "    gmm = GaussianMixture(n_components=num_components,\n",
    "                          covariance_type=cov_type)\n",
    "\n",
    "    gmm.fit(df)\n",
    "\n",
    "    return gmm.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbscan_labels(df, eps_value, minimum_samples):\n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    dbscan = DBSCAN(eps=eps_value, min_samples=minimum_samples)\n",
    "\n",
    "    dbscan.fit(df)\n",
    "\n",
    "    return dbscan.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_labels(df, **kwargs):\n",
    "    import pandas as pd\n",
    "\n",
    "    labels_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        km_labels = get_kmeans_labels(df, index)\n",
    "        gmm_labels = get_hierarquico_labels(df, index, kwargs.get('linkage'))\n",
    "        em_labels = get_em_labels(df, index, kwargs.get('cov_type'))\n",
    "        dbscan_labels = get_dbscan_labels(df, kwargs.get('eps_value'), index)\n",
    "\n",
    "        labels_values = {'Grupos': index, 'Kmeans': km_labels,\n",
    "                         'Hierarquico': gmm_labels, 'EM': em_labels, 'DBSCAN': dbscan_labels}\n",
    "\n",
    "        labels_data.append(labels_values)\n",
    "\n",
    "    df_labels = pd.DataFrame(labels_data)\n",
    "    df_labels.index = df_labels.index + 2\n",
    "\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_indices(df, labels, models_labels, is_corr):\n",
    "    import pandas as pd\n",
    "\n",
    "    indices_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        db_value_km, sil_value_km, cr_value_km = get_indices_values(\n",
    "            df, labels, models_labels.loc[index, 'Kmeans'])\n",
    "        db_value_hiera, sil_value_hiera, cr_value_hiera = get_indices_values(\n",
    "            df, labels, models_labels.loc[index, 'Hierarquico'])\n",
    "        db_value_em, sil_value_em, cr_value_em = get_indices_values(\n",
    "            df, labels, models_labels.loc[index, 'EM'])\n",
    "        if not is_corr:\n",
    "            db_value_dbscan, sil_value_dbscan, cr_value_dbscan = get_indices_values(\n",
    "                df, labels, models_labels.loc[index, 'DBSCAN'])\n",
    "\n",
    "        indices_values = {\n",
    "            'Grupos': index,\n",
    "            'Kmeans': {'DB': db_value_km, 'SIL': sil_value_km, 'CR': cr_value_km},\n",
    "            'Hierarquico': {'DB': db_value_hiera, 'SIL': sil_value_hiera, 'CR': cr_value_hiera},\n",
    "            'EM': {'DB': db_value_em, 'SIL': sil_value_em, 'CR': cr_value_em},\n",
    "        }\n",
    "\n",
    "        if not is_corr:\n",
    "            indices_values.update(\n",
    "                {'DBSCAN': {'DB': db_value_dbscan, 'SIL': sil_value_dbscan, 'CR': cr_value_dbscan}})\n",
    "\n",
    "        indices_data.append(indices_values)\n",
    "\n",
    "    df_indices = pd.DataFrame(indices_data)\n",
    "    df_indices.index = df_indices.index + 2\n",
    "\n",
    "    return df_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_indices(df_orig, df_corr, df_pca, cluster_type):\n",
    "    import pandas as pd\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    indices_list = ['DB', 'SIL', 'CR']\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=3, subplot_titles=(\n",
    "        'Índice - Davies-Bouldin', 'Índice - Silhouette', 'Índice - Adjusted Rand Score'))\n",
    "\n",
    "    for index, indice in enumerate(indices_list, 1):\n",
    "        fig.add_trace(go.Scatter(x=df_orig['Grupos'], y=df_orig[cluster_type].apply(\n",
    "            lambda x: x[indice]), name='Base original'), row=1, col=index)\n",
    "        if cluster_type != 'DBSCAN':\n",
    "            fig.add_trace(go.Scatter(x=df_corr['Grupos'], y=df_corr[cluster_type].apply(\n",
    "                lambda x: x[indice]), name='Correlação'), row=1, col=index)\n",
    "        fig.add_trace(go.Scatter(x=df_pca['Grupos'], y=df_pca[cluster_type].apply(\n",
    "            lambda x: x[indice]), name='PCA'), row=1, col=index)\n",
    "\n",
    "    fig.update_layout(title=f'Gráfico de {\n",
    "                      cluster_type.upper()}', showlegend=True, boxmode='group')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geração de gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_models_labels = get_models_labels(\n",
    "    data_tfidf, linkage='ward', cov_type='full', eps_value=.1)\n",
    "pca_models_labels = get_models_labels(\n",
    "    selected_df_pca, linkage='ward', cov_type='full', eps_value=.1)\n",
    "corr_models_labels = get_models_labels(\n",
    "    selected_df_corr, linkage='ward', cov_type='full', eps_value=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cluster_indices = get_cluster_indices(\n",
    "    data_tfidf, labels, original_models_labels, False)\n",
    "pca_cluster_indices = get_cluster_indices(\n",
    "    selected_df_pca, labels, pca_models_labels, False)\n",
    "corr_cluster_indices = get_cluster_indices(\n",
    "    selected_df_corr, labels, corr_models_labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade jupyter notebook jupyterlab plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices,\n",
    "                     corr_cluster_indices, pca_cluster_indices, 'Kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices,\n",
    "                     corr_cluster_indices, pca_cluster_indices, 'Hierarquico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices,\n",
    "                     corr_cluster_indices, pca_cluster_indices, 'EM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices,\n",
    "                     corr_cluster_indices, pca_cluster_indices, 'DBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comitê de Agrupamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_binary_matrix(clabels):\n",
    "    from scipy import sparse\n",
    "\n",
    "    data_len = len(clabels)\n",
    "\n",
    "    matrix = np.zeros((data_len, data_len))\n",
    "\n",
    "    for index in range(data_len):\n",
    "        matrix[index, :] = clabels == clabels[index]\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(models_labels):\n",
    "    n_runs, n_data = models_labels.shape[0], models_labels.shape[1]\n",
    "\n",
    "    sim_matrix = np.zeros((n_data, n_data))\n",
    "\n",
    "    for index in range(n_runs):\n",
    "        sim_matrix += build_binary_matrix(models_labels[index, :])\n",
    "\n",
    "    sim_matrix = sim_matrix / n_runs\n",
    "\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_indices(df, final_labels, labels):\n",
    "    from sklearn.metrics import davies_bouldin_score, silhouette_score, adjusted_rand_score\n",
    "\n",
    "    indice_db = davies_bouldin_score(df, final_labels)\n",
    "    indice_sil = silhouette_score(df, final_labels, metric='euclidean')\n",
    "    indice_cr = adjusted_rand_score(labels, final_labels)\n",
    "\n",
    "    return indice_db, indice_sil, indice_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_labels_en(df: pd.DataFrame, num_clusters):\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    km_model = KMeans(n_clusters=num_clusters, n_init=4, random_state=214)\n",
    "    km_model.fit(df)\n",
    "\n",
    "    return km_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hierarquico_labels_en(df: pd.DataFrame, num_clusters):\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "    agglo_model = AgglomerativeClustering(n_clusters=num_clusters)\n",
    "    agglo_model.fit(df)\n",
    "\n",
    "    return agglo_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_em_labels_en(df: pd.DataFrame, num_components):\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "\n",
    "    gmm_model = GaussianMixture(n_components=num_components, random_state=214)\n",
    "\n",
    "    gmm_model.fit(df)\n",
    "    labels = gmm_model.predict(df)\n",
    "\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbscan_labels_en(df, eps, min_samples):\n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    dbscan_models = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "\n",
    "    dbscan_models.fit(df)\n",
    "\n",
    "    return dbscan_models.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_matrix_en(models_labels: np.ndarray):\n",
    "\n",
    "    return build_similarity_matrix(models_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_labels_en(sim_matrix, num_clusters):\n",
    "    from sklearn.cluster import SpectralClustering\n",
    "\n",
    "    spec_clt = SpectralClustering(n_clusters=num_clusters, affinity='precomputed',\n",
    "                                  n_init=5, random_state=214)\n",
    "\n",
    "    final_labels = spec_clt.fit_predict(sim_matrix)\n",
    "\n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_df(df: pd.DataFrame, labels: np.ndarray, **kwargs) -> pd.DataFrame:\n",
    "    import pandas as pd\n",
    "\n",
    "    indices_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        db_df, sil_df, cr_df = {}, {}, {}\n",
    "\n",
    "        kmeans_labels = get_kmeans_labels_en(df, index)\n",
    "        hierarquico_labels = get_hierarquico_labels_en(df, index)\n",
    "        em_labels = get_em_labels_en(df, index)\n",
    "        dbscan_labels = get_dbscan_labels_en(df, .1, index)\n",
    "\n",
    "        models_labels = np.array(\n",
    "            [kmeans_labels, hierarquico_labels, em_labels, dbscan_labels])\n",
    "\n",
    "        sim_matrix = get_similarity_matrix_en(models_labels)\n",
    "\n",
    "        final_labels = get_final_labels_en(sim_matrix, index)\n",
    "\n",
    "        db_value, sil_value, cr_value = get_ensemble_indices(\n",
    "            df, final_labels, labels)\n",
    "\n",
    "        indice_values = {'Grupos': index, 'DB': db_value,\n",
    "                         'Silhouette': sil_value, 'CR': cr_value, 'Labels': final_labels}\n",
    "        indices_data.append(indice_values)\n",
    "\n",
    "    indices_ensemble_df = pd.DataFrame(indices_data)\n",
    "    indices_ensemble_df.index = indices_ensemble_df.index + 2\n",
    "\n",
    "    return indices_ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ensemble_indices(en_df_original: pd.DataFrame, en_df_corr: pd.DataFrame, en_df_pca: pd.DataFrame, indice_name: str) -> None:\n",
    "    import pandas as pd\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    indice_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        indice_values = {'Grupos': index + 2,\n",
    "                         'Original': en_df_original.loc[index, indice_name],\n",
    "                         'Correlação': en_df_corr.loc[index, indice_name],\n",
    "                         'PCA': en_df_pca.loc[index, indice_name]\n",
    "                         }\n",
    "        indice_data.append(indice_values)\n",
    "\n",
    "    df = pd.DataFrame(indice_data)\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1, subplot_titles=(\n",
    "        f'Índice - {indice_name}'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['Grupos'], y=df['Original'], name='Base original'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['Grupos'], y=df['Correlação'], name='Correlação'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df['Grupos'],\n",
    "                  y=df['PCA'], name='PCA'), row=1, col=1)\n",
    "\n",
    "    fig.update_layout(title=f'Gráfico de comitê de agrupamento - Índice {\n",
    "                      indice_name}', showlegend=True, boxmode='group')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_df_original = get_ensemble_df(data_tfidf, labels)\n",
    "ensemble_df_corr = get_ensemble_df(selected_df_corr, labels)\n",
    "ensemble_df_pca = get_ensemble_df(selected_df_pca, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble_indices(ensemble_df_original,\n",
    "                      ensemble_df_corr, ensemble_df_pca, 'DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble_indices(ensemble_df_original, ensemble_df_corr,\n",
    "                      ensemble_df_pca, 'Silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble_indices(ensemble_df_original,\n",
    "                      ensemble_df_corr, ensemble_df_pca, 'CR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste Estatístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cr_df() -> pd.DataFrame:\n",
    "    cr_data = pd.DataFrame(columns=[\n",
    "        'kmeans', 'hierarquico', 'em', 'dbscan', 'ensemble'\n",
    "    ], index=range(2, 21))\n",
    "\n",
    "    return cr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cr_values(df, ensemble_df):\n",
    "    result_df = get_cr_df()\n",
    "\n",
    "    km_cr_values = df['Kmeans'].apply(lambda x: x['CR'])\n",
    "    ag_cr_values = df['Hierarquico'].apply(lambda x: x['CR'])\n",
    "    em_cr_values = df['EM'].apply(lambda x: x['CR'])\n",
    "    dbscan_cr_values = df['DBSCAN'].apply(lambda x: x['CR'])\n",
    "\n",
    "    for num_cluster in range(2, 21):\n",
    "        result_df.loc[num_cluster] = [\n",
    "            km_cr_values.loc[num_cluster],\n",
    "            ag_cr_values.loc[num_cluster],\n",
    "            em_cr_values.loc[num_cluster],\n",
    "            dbscan_cr_values.loc[num_cluster],\n",
    "            ensemble_df.loc[num_cluster, 'CR']\n",
    "        ]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cr_values_corr(df, ensemble_df):\n",
    "    result_df = get_cr_df()\n",
    "    result_df = result_df.drop('dbscan', axis=1)\n",
    "\n",
    "    km_cr_values = df['Kmeans'].apply(lambda x: x['CR'])\n",
    "    ag_cr_values = df['Hierarquico'].apply(lambda x: x['CR'])\n",
    "    em_cr_values = df['EM'].apply(lambda x: x['CR'])\n",
    "\n",
    "    for num_cluster in range(2, 21):\n",
    "        result_df.loc[num_cluster] = [\n",
    "            km_cr_values.loc[num_cluster],\n",
    "            ag_cr_values.loc[num_cluster],\n",
    "            em_cr_values.loc[num_cluster],\n",
    "            ensemble_df.loc[num_cluster, 'CR']\n",
    "        ]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_friedman_result(df):\n",
    "    from scipy.stats import friedmanchisquare\n",
    "\n",
    "    friedman_chi2, friedman_p_value = friedmanchisquare(\n",
    "        *[df[col] for col in df.columns])\n",
    "    print(\"Teste de Friedman\")\n",
    "    print(f\"p-valor: {friedman_p_value:.4f}\")\n",
    "    print(f\"qui-quadrado: {friedman_chi2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nemenyi_result(df):\n",
    "    from scikit_posthocs import posthoc_nemenyi_friedman\n",
    "\n",
    "    nemenyi_results = posthoc_nemenyi_friedman(df)\n",
    "    print(\"Teste Nemenyi (pós-hoc):\")\n",
    "    print(nemenyi_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nemenyi_result(df, title):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scikit_posthocs import posthoc_nemenyi_friedman\n",
    "\n",
    "    nemenyi_results = posthoc_nemenyi_friedman(df)\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.heatmap(nemenyi_results, annot=True, cmap='coolwarm', fmt=\".4f\", cbar=True,\n",
    "                linewidths=0.5, linecolor='black', vmin=0, vmax=1)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_original = fill_cr_values(original_cluster_indices, ensemble_df_original)\n",
    "cr_pca = fill_cr_values(pca_cluster_indices, ensemble_df_pca)\n",
    "cr_corr = fill_cr_values_corr(corr_cluster_indices, ensemble_df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original\")\n",
    "print_friedman_result(cr_original)\n",
    "print(\"Corr\")\n",
    "print_friedman_result(cr_corr)\n",
    "print(\"PCA\")\n",
    "print_friedman_result(cr_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original\")\n",
    "print_nemenyi_result(cr_original)\n",
    "print(\"Corr\")\n",
    "print_nemenyi_result(cr_corr)\n",
    "print(\"PCA\")\n",
    "print_nemenyi_result(cr_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nemenyi_result(cr_original, \"Teste Nemenyi (pós-hoc) - Original\")\n",
    "plot_nemenyi_result(cr_corr, \"Teste Nemenyi (pós-hoc) - Correlação\")\n",
    "plot_nemenyi_result(cr_pca, \"Teste Nemenyi (pós-hoc) - PCA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
