{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to develop and evaluate machine learning models to assess performance and conduct a comparative analysis of the results. We have selected Logistic Regression and Random Forest as the primary models for this study, allowing us to draw informed conclusions based on their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Logistic Regression?\n",
    "\n",
    "Simplicity and Interpretability: Logistic Regression is a straightforward and interpretable model. It provides probabilities that can be easily understood and translated into decision-making. The coefficients of the model indicate the influence of each feature on the outcome, making it easier to interpret and understand the relationship between the variables.\n",
    "\n",
    "Linear Decision Boundary: Logistic Regression assumes a linear relationship between the features and the outcome. This can be beneficial when the true relationship is approximately linear, allowing for efficient and effective modeling. It provides a clear decision boundary that separates classes based on a linear combination of the input features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming categorical variables into dummies\n",
    "X = pd.get_dummies(df.drop(columns=['resultado']), drop_first=True)\n",
    "y = df['resultado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the target variable into numerical values\n",
    "y = df['resultado'].map({'DEFERIDO': 1, 'INDEFERIDO': 0, 'NÃO DEFINIDO': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset, training and making previsions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Logistic Regression model for multiclass classification\n",
    "model = LogisticRegression(multi_class='ovr')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_logistic = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating\n",
    "accuracy = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f'Acuracy: {accuracy:.2f}')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_logistic)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "class_report = classification_report(y_test, y_pred_logistic)\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Random Forest?\n",
    "\n",
    "Non-Linearity: Unlike Logistic Regression, which assumes a linear relationship between the variables and the outcome, Random Forest can capture more complex interactions.\n",
    "\n",
    "Immune to Overfitting: Since it is an ensemble of multiple trees, it tends to be more resistant to overfitting.\n",
    "\n",
    "Interpretability: You can obtain the feature importance, which helps to understand which features have the most impact on the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the categorical variables have already been transformed\n",
    "X = pd.get_dummies(df.drop(columns=['resultado']), drop_first=True)\n",
    "y = df['resultado'].map({'DEFERIDO': 1, 'INDEFERIDO': 0, 'NÃO DEFINIDO': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Creating and training the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Acuracy: {accuracy:.2f}')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "class_report = classification_report(y_test, y_pred_rf)\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the predicted probabilities\n",
    "y_prob_lr = model.predict_proba(X_test)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "# ROC Curves\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr[:, 1], pos_label=1)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf[:, 1], pos_label=1)\n",
    "\n",
    "# AUC (Area Under the Curve)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# Plotting the ROC Curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_lr, tpr_lr, color='blue',\n",
    "         label=f'Logistic Regression (AUC = {roc_auc_lr:.2f})')\n",
    "plt.plot(fpr_rf, tpr_rf, color='green',\n",
    "         label=f'Random Forest (AUC = {roc_auc_rf:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Supondo que você já tenha os valores reais e as previsões dos modelos\n",
    "# y_true = valores reais\n",
    "# y_pred_logistic = previsões do modelo de Regressão Logística\n",
    "# y_pred_rf = previsões do modelo de Random Forest\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['INDEFERIDO', 'DEFERIDO', 'NÃO DEFINIDO'],\n",
    "                yticklabels=['INDEFERIDO', 'DEFERIDO', 'NÃO DEFINIDO'])\n",
    "    # plt.title(f'Matriz de Confusão - {model_name}', fontsize=14)\n",
    "    plt.ylabel('Valores Reais', fontsize=12)\n",
    "    plt.xlabel('Valores Previstos', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Exemplo de uso com Regressão Logística\n",
    "plot_confusion_matrix(y_test, y_pred_logistic, \"Regressão Logística\")\n",
    "\n",
    "# Exemplo de uso com Random Forest\n",
    "plot_confusion_matrix(y_test, y_pred_rf, \"Random Forest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
