{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajxqeWPm-QWE"
   },
   "source": [
    "# Install necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mKWsHLsz-O_k"
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pdf_folder = '../data'\n",
    "\n",
    "pdf_files_path = []\n",
    "for root, dirs, files in os.walk(pdf_folder):\n",
    "  for file in files:\n",
    "    if file.endswith('.pdf'):\n",
    "      pdf_files_path.append(os.path.join(root, file))\n",
    "\n",
    "raw_texts = []\n",
    "\n",
    "for pdf_file_path in pdf_files_path:\n",
    "  whole_text = ''\n",
    "\n",
    "  with pdfplumber.open(pdf_file_path) as pdf:\n",
    "    for index, page in enumerate(pdf.pages):\n",
    "      text = page.extract_text()\n",
    "      if index > 0:\n",
    "        whole_text += f\"page: {index} {text}\\n\"\n",
    "      else:\n",
    "        whole_text += f\"{text}\\n\"\n",
    "\n",
    "  raw_texts.append(whole_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract unstructured text from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYhpBB4oDlA_"
   },
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(data={'raw': raw_texts})\n",
    "\n",
    "row_count = dataframe.count()\n",
    "columns = dataframe.columns\n",
    "print(f\"Row count: {row_count}\")\n",
    "print(f\"Columns: {columns}\")\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_based_on_appearance_in_text(text_to_extract: str, text: str, type: str = 'after'):\n",
    "  \"\"\"\n",
    "  Extracts the text after the appearance of a specific text in a given string.\n",
    "\n",
    "  Parameters:\n",
    "    text_to_extract (str): The text to extract.\n",
    "    text (str): The input string.\n",
    "    type (str): The type of extraction. It can be either \"before\" or \"after\".\n",
    "\n",
    "  Returns:\n",
    "    str: The extracted text.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If the type is neither \"before\" nor \"after\".\n",
    "  \"\"\"\n",
    "\n",
    "  import re\n",
    "\n",
    "  if type == 'before':\n",
    "    search = re.search(rf'.*(?<={text_to_extract})', text, re.DOTALL)\n",
    "  elif type == 'after':\n",
    "    search = re.search(rf'(?<={text_to_extract}).*', text)\n",
    "  else:\n",
    "    raise ValueError('type must be either \"before\" or \"after\"')\n",
    "\n",
    "  extracted_text = search.group().strip() if search else None\n",
    "\n",
    "  return extracted_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all essential data from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "def extract_needed_information_from_pdf_text(text: str):\n",
    "  \"\"\"\n",
    "  Extracts the needed information from a given PDF text.\n",
    "\n",
    "  Parameters:\n",
    "    text (str): The input text.\n",
    "\n",
    "  Returns:\n",
    "    dict: The extracted information.\n",
    "  \"\"\"\n",
    "\n",
    "  # Remove redundant texts that are not useful for the analysis\n",
    "  text = re.sub(r'\\bTribunal Regional Eleitoral do Rio Grande do Norte\\n\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\bPJe - Processo Judicial Eletrônico\\n\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\bN úmero: \\b', '', text, count=1)\n",
    "  # Extracting the date of process\n",
    "  date_pattern = r'\\d{2}/\\d{2}/\\d{4}'\n",
    "  date_match = re.search(date_pattern, text)\n",
    "  date = date_match.group() if date_match else None \n",
    "  print(date)\n",
    "\n",
    "  text = re.sub(date_pattern, '\\n', text, count=1)\n",
    "\n",
    "  # Extracting the legal action number\n",
    "  legal_action_number_pattern = r'\\b\\d{7}-\\d{2}.\\d{4}.\\d{1}.\\d{2}.\\d{4}\\b' \n",
    "  legal_action_number_match = re.search(legal_action_number_pattern, text)\n",
    "  legal_action_number = legal_action_number_match.group() if legal_action_number_match else None\n",
    "  text = re.sub(legal_action_number_pattern, '\\n', text, count=1)\n",
    "  print(legal_action_number)\n",
    "\n",
    "\n",
    "  # Extracting the data of raw text\n",
    "  search = 'Classe:'\n",
    "  legal_class = extract_text_based_on_appearance_in_text(search, text)\n",
    "  print(legal_class)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {legal_class}\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Órgão julgador:'\n",
    "  tribunal = extract_text_based_on_appearance_in_text(search, text)\n",
    "  print(tribunal)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {tribunal}\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Última distribuição :'\n",
    "  last_distribution = extract_text_based_on_appearance_in_text('Última distribuição :', text)\n",
    "  print(last_distribution)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {last_distribution}\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Valor da causa:'\n",
    "  cause_cost = extract_text_based_on_appearance_in_text('Valor da causa:', text)\n",
    "  print(f'cause cost: {cause_cost}')\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {cause_cost}\\n\\b', '', text, count=1)\n",
    "  text = re.sub(r'R\\$', '', text, count=1)\n",
    "\n",
    "  search = 'Processo referência:'\n",
    "  reference_legal_action = extract_text_based_on_appearance_in_text('Processo referência:', text)\n",
    "  print(reference_legal_action)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {reference_legal_action}\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Assuntos:'\n",
    "  matters = extract_text_based_on_appearance_in_text('Assuntos:', text)\n",
    "  print(matters)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {matters}\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Cargo -'\n",
    "  position = extract_text_based_on_appearance_in_text('Cargo -', text)\n",
    "  print(position)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {position}\\n\\b', '', text, count=1)\n",
    "\n",
    "  legal_action_goal_string = 'Objeto do processo: '\n",
    "  judicial_secrecy = 'Segredo de Justiça?'\n",
    "  extracted_text = re.search(f'{legal_action_goal_string}(.*?){judicial_secrecy}', text, re.DOTALL)\n",
    "  legal_action_goal = extracted_text.group(1).strip() if extracted_text else None\n",
    "  print(legal_action_goal)\n",
    "\n",
    "  text = re.sub(rf'\\b{legal_action_goal_string}\\b', '', text.strip(), count=1)\n",
    "  legal_action_goal = legal_action_goal.replace('\\n', ' ').strip()\n",
    "\n",
    "  legal_action_goal_splitted = legal_action_goal.split(' ')\n",
    "\n",
    "  for word in legal_action_goal_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "\n",
    "  text = text.strip()\n",
    "\n",
    "  search = 'Segredo de Justiça\\?'\n",
    "  judicial_secrecy = extract_text_based_on_appearance_in_text('Segredo de Justiça\\?', text)\n",
    "  print(judicial_secrecy)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {judicial_secrecy}\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Justiça gratuita\\?'\n",
    "  free_judicial = extract_text_based_on_appearance_in_text('Justiça gratuita\\?', text)\n",
    "  print(free_judicial)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {free_judicial}\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Pedido de liminar ou antecipação de tutela\\?'\n",
    "  formal_request = extract_text_based_on_appearance_in_text('Pedido de liminar ou antecipação de tutela\\?', text)\n",
    "  print(formal_request)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {formal_request}\\b', '', text, count=1)\n",
    "\n",
    "  text = re.sub(r'\\bPartes Advogados\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = r'\\(REQUERENTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' '))\n",
    "  requerente = match.group(1).strip() if match else None\n",
    "  print(requerente)\n",
    "\n",
    "  text = re.sub(r'\\b(REQUERENTE)\\b', '', text, count=1)\n",
    "  requerente_splitted = requerente.split(' ') if requerente != None else []\n",
    "  for word in requerente_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(IMPUGNANTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  impugnante = match.group(1).strip() if match else None\n",
    "  print(f'impugnante: {impugnante}')\n",
    "\n",
    "  text = re.sub(r'\\b(IMPUGNANTE)\\b', '', text, count=1)\n",
    "  text = text.strip()\n",
    "  impugnante_splitted = impugnante.split(' ') if impugnante != None else []\n",
    "  for word in impugnante_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(IMPUGNANTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  impugnante_2 = match.group(1).strip() if match else None\n",
    "  print(f'impugnante: {impugnante_2}')\n",
    "\n",
    "  text = re.sub(r'\\b(IMPUGNANTE)\\b', '', text, count=1)\n",
    "  text = text.strip()\n",
    "  impugnante_splitted_2 = impugnante_2.split(' ') if impugnante_2 != None else []\n",
    "  for word in impugnante_splitted_2:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  # print(text)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(IMPUGNADO\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  impugnado = match.group(1).strip() if match else None\n",
    "  print(f\"impugnado: {impugnado}\")\n",
    "\n",
    "  text = re.sub(r'\\b(IMPUGNADO)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{impugnado}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(ADVOGADO\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' '))\n",
    "  advogado = match.group(1).strip() if match else None\n",
    "  print(advogado)\n",
    "\n",
    "  advogado_splitted = advogado.split(' ') if advogado != None else []\n",
    "  for word in advogado_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\b(ADVOGADO)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{advogado}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(IMPUGNADO\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  impugnado_2 = match.group(1).strip() if match else None\n",
    "  print(f\"impugnado 2: {impugnado_2}\")\n",
    "\n",
    "  text = re.sub(r'\\b(IMPUGNADO)\\b', '', text, count=1)\n",
    "  text = text.strip()\n",
    "  impugnado_splitted_2 = impugnado_2.split(' ') if impugnado_2 != None else []\n",
    "  for word in impugnado_splitted_2:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(REQUERENTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  requerente_2 = match.group(1).strip() if match else None\n",
    "  print(requerente_2)\n",
    "  \n",
    "  requerente2_splitted = requerente_2.split(' ') if requerente_2 != None else []\n",
    "  for word in requerente2_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\b(REQUERENTE)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{requerente_2}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(ADVOGADO\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' '))\n",
    "  advogado_2 = match.group(1).strip() if match else None\n",
    "  print(f\"advogado 2: {advogado_2}\")\n",
    "\n",
    "  text = re.sub(r'\\b(ADVOGADO)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{advogado_2}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(REQUERENTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  requerente_3 = match.group(1).strip() if match else None\n",
    "  print(requerente_3)\n",
    "\n",
    "  requerente3_splitted = requerente_3.split(' ') if requerente_3 != None else []\n",
    "  for word in requerente3_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\b(REQUERENTE)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{requerente_3}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(REQUERENTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  requerente_4 = match.group(1).strip() if match else None\n",
    "  print(requerente_4)\n",
    "\n",
    "  requerente4_splitted = requerente_4.split(' ') if requerente_4 != None else []\n",
    "  for word in requerente4_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\b(REQUERENTE)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{requerente_4}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(REQUERENTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  requerente_5 = match.group(1).strip() if match else None\n",
    "  print(requerente_5)\n",
    "\n",
    "  requerente5_splitted = requerente_5.split(' ') if requerente_5 != None else []\n",
    "  for word in requerente5_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\b(REQUERENTE)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{requerente_5}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(REQUERENTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  requerente_6 = match.group(1).strip() if match else None\n",
    "  print(requerente_6)\n",
    "\n",
    "  requerente6_splitted = requerente_6.split(' ') if requerente_6 != None else []\n",
    "  for word in requerente6_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\b(REQUERENTE)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{requerente_6}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(REQUERENTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  requerente_7 = match.group(1).strip() if match else None\n",
    "  print(requerente_7)\n",
    "\n",
    "  requerente7_splitted = requerente_7.split(' ') if requerente_7 != None else []\n",
    "  for word in requerente7_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\b(REQUERENTE)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{requerente_7}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(REQUERENTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  requerente_8 = match.group(1).strip() if match else None\n",
    "  print(requerente_8)\n",
    "\n",
    "  requerente8_splitted = requerente_8.split(' ') if requerente_8 != None else []\n",
    "  for word in requerente8_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\b(REQUERENTE)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{requerente_8}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  outros_participantes_search = 'Outros participantes'\n",
    "  fiscal_de_lei_search = r'\\(FISCAL DA LEI\\)'\n",
    "  extracted_text = re.search(f'{outros_participantes_search}(.*?){fiscal_de_lei_search}', text, re.DOTALL)\n",
    "  fiscal_de_lei_nome = extracted_text.group(1).strip().replace('\\n', ' ') if extracted_text else None\n",
    "  print(fiscal_de_lei_nome)\n",
    "\n",
    "  text = re.sub(rf'\\b{outros_participantes_search}\\n\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\bFISCAL DA LEI\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "  text = re.sub(r'\\bPROMOTOR ELEITORAL DO ESTADO DO RIO GRANDE DO\\nNORTE\\b', '', text, count=1)\n",
    "\n",
    "  text = re.sub(r'\\bDocumentos\\b', '', text, count=1)\n",
    "\n",
    "  text_treated_for_index = text.strip().replace('\\n', ' ').split(' ')\n",
    "\n",
    "  print(text_treated_for_index)\n",
    "\n",
    "  text_treated_for_index.remove('Id.')\n",
    "  text_treated_for_index.remove('Data')\n",
    "  text_treated_for_index.remove('da')\n",
    "  text_treated_for_index.remove('Documento')\n",
    "  text_treated_for_index.remove('Tipo')\n",
    "  text_treated_for_index.remove('Assinatura')\n",
    "\n",
    "  print(text_treated_for_index)\n",
    "\n",
    "  id = text_treated_for_index[0]\n",
    "  print(f\"id: {id}\")\n",
    "  \n",
    "  text_treated_for_index.pop(0)\n",
    "\n",
    "  data_da_assinatura = text_treated_for_index[0]\n",
    "  print(f\"data: {data_da_assinatura}\")\n",
    "  text_treated_for_index.pop(0)\n",
    "\n",
    "  initial_index = 0\n",
    "\n",
    "  for index, word in enumerate(text_treated_for_index, start=initial_index):\n",
    "    pattern = r'\\d{2}:\\d{2}'\n",
    "    match = re.match(pattern, word)\n",
    "\n",
    "    if match:\n",
    "      hora_da_assinatura = word\n",
    "      break\n",
    "\n",
    "  text_treated_for_index.remove(hora_da_assinatura)\n",
    "  \n",
    "\n",
    "  data_hora_da_assinatura = f'{data_da_assinatura} {hora_da_assinatura}'\n",
    "  data_hora_da_assinatura_timestamp = datetime.datetime.strptime(data_hora_da_assinatura, '%d/%m/%Y %H:%M').isoformat()\n",
    "  print(data_hora_da_assinatura_timestamp)\n",
    "\n",
    "  tipo = ''\n",
    "\n",
    "  for index, word in enumerate(text_treated_for_index):\n",
    "    if word == 'Sentença' or word == 'Petição':\n",
    "      tipo = word\n",
    "      break\n",
    "    elif word == 'Outros' and text_treated_for_index[index + 1] == 'documentos':\n",
    "      tipo = f'{word} {text_treated_for_index[index + 1]}'\n",
    "      break\n",
    "    elif word == 'Parecer' and text_treated_for_index[index + 1] == 'da' and text_treated_for_index[index + 1] == 'Procuradoria':\n",
    "      tipo = f'{word} {text_treated_for_index[index + 1]} {text_treated_for_index[index + 2]}'\n",
    "      break\n",
    "    elif word == 'Cota' and text_treated_for_index[index + 1] == 'ministerial':\n",
    "      tipo = f'{word} {text_treated_for_index[index + 1]}'\n",
    "      break\n",
    "\n",
    "  print(tipo)\n",
    "  if tipo == 'Sentença' or tipo == 'Petição':\n",
    "    text_treated_for_index.remove(tipo)\n",
    "  elif tipo == 'Outros documentos':\n",
    "    text_treated_for_index.remove('Outros')\n",
    "    text_treated_for_index.remove('documentos')\n",
    "  elif tipo == 'Parecer da Procuradoria':\n",
    "    text_treated_for_index.remove('Parecer')\n",
    "    text_treated_for_index.remove('da')\n",
    "    text_treated_for_index.remove('Procuradoria')\n",
    "  elif tipo == 'Cota ministerial':\n",
    "    text_treated_for_index.remove('Cota')\n",
    "    text_treated_for_index.remove('ministerial')\n",
    "\n",
    "  index = text_treated_for_index.index('page:')\n",
    "  \n",
    "  documento = ' '.join(text_treated_for_index[:index])\n",
    "  print(documento)\n",
    "\n",
    "  resultado = 'NÃO DEFINIDO'\n",
    "\n",
    "  detalhamento = ' '.join(text_treated_for_index[index+2:])\n",
    "  print(detalhamento)\n",
    "  \n",
    "  indeferimento_word_appearance = detalhamento.lower().find('indefiro')\n",
    "\n",
    "  if detalhamento.lower().find('defiro') != -1:\n",
    "    resultado = 'DEFERIDO'\n",
    "  elif detalhamento.lower().find('deferimento') != -1:\n",
    "    resultado = 'DEFERIDO'\n",
    "  elif detalhamento.lower().find('manifesta-se pelo deferimento') != -1:\n",
    "    resultado = 'DEFERIDO'\n",
    "  elif detalhamento.lower().find('homologo') != -1:\n",
    "    resultado = 'DEFERIDO'\n",
    "\n",
    "\n",
    "  if indeferimento_word_appearance != -1:\n",
    "    resultado = 'INDEFERIDO'\n",
    "  elif detalhamento.lower().find('indeferindo-se') != -1:\n",
    "    resultado = 'INDEFERIDO'\n",
    "  elif detalhamento.lower().find('indeferimento') != -1:\n",
    "    resultado = 'INDEFERIDO'\n",
    "  elif detalhamento.lower().find('litispendência') != -1:\n",
    "    resultado = 'INDEFERIDO'\n",
    "  elif detalhamento.lower().find('não foram preenchidas') != -1:\n",
    "    resultado = 'INDEFERIDO'\n",
    "  elif detalhamento.lower().find('extinguo') != -1:\n",
    "    resultado = 'INDEFERIDO'\n",
    "  elif detalhamento.lower().find('ausência de documentos exigidos') != -1:\n",
    "    resultado = 'INDEFERIDO'\n",
    "\n",
    "  \n",
    "  print(resultado)\n",
    "\n",
    "  data = {\n",
    "    'advogado': advogado,\n",
    "    'advogado_2': advogado_2,\n",
    "    'data_hora_da_assinatura_timestamp': data_hora_da_assinatura_timestamp,\n",
    "    'documento': documento,\n",
    "    'detalhamento': detalhamento,\n",
    "    'fiscal_de_lei_nome': fiscal_de_lei_nome,\n",
    "    'formal_request': formal_request,\n",
    "    'free_judicial': free_judicial,\n",
    "    'id': id,\n",
    "    'judicial_secrecy': judicial_secrecy,\n",
    "    'last_distribution': last_distribution,\n",
    "    'legal_action_goal': legal_action_goal,\n",
    "    'legal_action_number': legal_action_number,\n",
    "    'legal_class': legal_class,\n",
    "    'matters': matters,\n",
    "    'position': position,\n",
    "    'reference_legal_action': reference_legal_action,\n",
    "    'requerente': requerente,\n",
    "    'requerente_2': requerente_2,\n",
    "    'requerente_3': requerente_3,\n",
    "    'requerente_4': requerente_4,\n",
    "    'requerente_5': requerente_5,\n",
    "    'requerente_6': requerente_6,\n",
    "    'requerente_7': requerente_7,\n",
    "    'requerente_8': requerente_8,\n",
    "    'impugnante': impugnante,\n",
    "    'impugnante_2': impugnante_2,\n",
    "    'impugnado': impugnado,\n",
    "    'impugnado_2': impugnado_2,\n",
    "    'resultado': resultado,\n",
    "  }\n",
    "\n",
    "  return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "pdf_files_path_with_error = []\n",
    "\n",
    "for index, raw_text in enumerate(dataframe['raw']):\n",
    "  try:\n",
    "    data = extract_needed_information_from_pdf_text(raw_text)\n",
    "    data['pdf_file_path'] = pdf_files_path[index]\n",
    "    new_row = pd.DataFrame([data])\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "  except ValueError:\n",
    "    pdf_files_path_with_error.append(pdf_files_path[index])\n",
    "    continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_files_path_with_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_defined = df[df.resultado == 'NÃO DEFINIDO']\n",
    "not_defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vetorizar documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessário para a NLTK\n",
    "nltk.download('stopwords')  # Baixa a lista de stop words (palavras comuns) para uso no processamento de texto\n",
    "nltk.download('punkt')  # Baixa o tokenizer Punkt, necessário para a tokenização de frases\n",
    "\n",
    "# Carregar o modelo de português para o spaCy\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(text):\n",
    "\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Converte para minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove pontuação\n",
    "    # []: colchetes são usados para definir uma classe de caracteres.\n",
    "    # ^: quando usado no início de uma classe de caracteres, o ^ nega a classe, ou seja, seleciona tudo que não está na classe.\n",
    "    # \\w: corresponde a qualquer caractere alfanumérico (letras e números, incluindo o caractere de sublinhado _)\n",
    "    # \\s: corresponde a qualquer espaço em branco (espaços, tabulações, quebras de linha).\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove underlines\n",
    "    text = re.sub(r'_+', '', text)\n",
    "\n",
    "    # Remove números\n",
    "    # \\d: corresponde a qualquer dígito (de 0 a 9).\n",
    "    # +: significa “um ou mais” do elemento precedente. Portanto, \\d+ corresponde a uma sequência de um ou mais dígitos consecutivos.\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "  # Obtém a lista de stopwords em português usando o NLTK e as converte para um conjunto para melhorar a eficiência da busca\n",
    "  stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "  # Divide o texto em palavras, remove as stopwords e então junta as palavras restantes de volta em uma string\n",
    "  text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df.resultado != 'NÃO DEFINIDO']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['detalhamento'] = data['detalhamento'].apply(remove_noise)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1]['detalhamento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['detalhamento'] = data['detalhamento'].apply(remove_stopwords)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data['detalhamento'][267]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Logistic Regression?\n",
    "\n",
    "Simplicity and Interpretability: Logistic Regression is a straightforward and interpretable model. It provides probabilities that can be easily understood and translated into decision-making. The coefficients of the model indicate the influence of each feature on the outcome, making it easier to interpret and understand the relationship between the variables.\n",
    "\n",
    "Linear Decision Boundary: Logistic Regression assumes a linear relationship between the features and the outcome. This can be beneficial when the true relationship is approximately linear, allowing for efficient and effective modeling. It provides a clear decision boundary that separates classes based on a linear combination of the input features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o modelo em português do spaCy para tokenização\n",
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "# # Passa o texto para o pipeline de processamento do spaCy. O resultado é um objeto doc, que contém as palavras e sentenças tokenizadas, além de outras informações linguísticas.\n",
    "# doc = nlp(text)\n",
    "\n",
    "# # Extrair sentenças como tokens\n",
    "# sentence_tokens = [sent.text for sent in doc.sents]\n",
    "\n",
    "# print(\"Tokens:\", sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = [token.text for token in doc]\n",
    "# print('Tokens:', tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    return tokens\n",
    "\n",
    "data['tokens'] = data['detalhamento'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'][267]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming e Lemmatização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stemming'] = data['tokens'].apply(apply_stemming)\n",
    "data['stemming'][267]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Tokeniza a frase em palavras\n",
    "palavras = word_tokenize(data['detalhamento'][267])\n",
    "\n",
    "# Aplica o stemming a cada palavra\n",
    "stemmed_words = [stemmer.stem(word) for word in palavras]\n",
    "\n",
    "print(\"Frase original:\", data['detalhamento'][267])\n",
    "print(\"Palavras após Stemming:\", stemmed_words)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lemming(doc):\n",
    "  doc = ' '.join(doc)\n",
    "\n",
    "  nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "  doc = nlp(doc)\n",
    "\n",
    "  lemmatized_words = [token.lemma_ for token in doc]\n",
    "  \n",
    "  return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemming'] = data['tokens'].apply(apply_lemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['detalhamento'][267]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pdf_file_path'][267]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemming'][267]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemming'][2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "# Ajustar e transformar os documentos em uma matriz TF-IDF\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(data['lemming'].apply(lambda x: ' '.join(x)))\n",
    "vocab = vectorizer_tfidf.get_feature_names_out()\n",
    "print(\"Representação TF-IDF:\\n\", X_tfidf.toarray())\n",
    "print(\"Vocabulário TF-IDF:\\n\", vocab)\n",
    "\n",
    "print(\"Vocabulário TF-IDF:\", vocab)\n",
    "# Imprime a matriz TF-IDF com rótulos de linha e coluna\n",
    "print(\"Matriz TF-IDF:\")\n",
    "print(\"Documento \", end=\"\")\n",
    "for i, doc in enumerate(X_tfidf.toarray()):\n",
    "    print(f\"Documento {i+1}:\", end=\"   \")\n",
    "    for word, tfidf in zip(vocab, X_tfidf[i].toarray()[0]):\n",
    "        if tfidf == 0:\n",
    "            continue\n",
    "        print(f\"{word}: {tfidf:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorizar dataframe using TFiDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['detalhamento'] = data['lemming'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf = data.drop(columns=['requerente_8', 'lemming', 'stemming', 'tokens', 'pdf_file_path', 'resultado'])\n",
    "columns = data_tfidf.columns\n",
    "\n",
    "for column in columns:\n",
    "  print(f'== {column} ==')\n",
    "  if data_tfidf[column].str.strip().any():\n",
    "    tfidf_matrix = vectorizer_tfidf.fit_transform(data_tfidf[column])\n",
    "\n",
    "    data_tfidf[column] = tfidf_matrix.toarray().mean(axis=1)\n",
    "  else:\n",
    "    data_tfidf[column] = df[column].replace('', 0)\n",
    "\n",
    "data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = data['resultado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.replace('DEFERIDO', 1)\n",
    "labels = labels.replace('INDEFERIDO', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data_tfidf, labels, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervied Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to develop and evaluate machine learning models to assess performance and conduct a comparative analysis of the results. We have selected Logistic Regression and Random Forest as the primary models for this study, allowing us to draw informed conclusions based on their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Logistic Regression?\n",
    "\n",
    "Simplicity and Interpretability: Logistic Regression is a straightforward and interpretable model. It provides probabilities that can be easily understood and translated into decision-making. The coefficients of the model indicate the influence of each feature on the outcome, making it easier to interpret and understand the relationship between the variables.\n",
    "\n",
    "Linear Decision Boundary: Logistic Regression assumes a linear relationship between the features and the outcome. This can be beneficial when the true relationship is approximately linear, allowing for efficient and effective modeling. It provides a clear decision boundary that separates classes based on a linear combination of the input features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming categorical variables into dummies\n",
    "X = pd.get_dummies(df.drop(columns=['resultado']), drop_first=True)\n",
    "y = df['resultado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the target variable into numerical values\n",
    "y = df['resultado'].map({'DEFERIDO': 1, 'INDEFERIDO': 0, 'NÃO DEFINIDO': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset, training and making previsions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Logistic Regression model for multiclass classification\n",
    "model = LogisticRegression(multi_class='ovr')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_logistic = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating\n",
    "accuracy = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f'Acuracy: {accuracy:.2f}')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_logistic)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "class_report = classification_report(y_test, y_pred_logistic)\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Random Forest?\n",
    "\n",
    "Non-Linearity: Unlike Logistic Regression, which assumes a linear relationship between the variables and the outcome, Random Forest can capture more complex interactions.\n",
    "\n",
    "Immune to Overfitting: Since it is an ensemble of multiple trees, it tends to be more resistant to overfitting.\n",
    "\n",
    "Interpretability: You can obtain the feature importance, which helps to understand which features have the most impact on the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the categorical variables have already been transformed\n",
    "X = pd.get_dummies(df.drop(columns=['resultado']), drop_first=True)\n",
    "y = df['resultado'].map({'DEFERIDO': 1, 'INDEFERIDO': 0, 'NÃO DEFINIDO': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Creating and training the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Acuracy: {accuracy:.2f}')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "class_report = classification_report(y_test, y_pred_rf)\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the predicted probabilities\n",
    "y_prob_lr = model.predict_proba(X_test)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "# ROC Curves\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr[:, 1], pos_label=1)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf[:, 1], pos_label=1)\n",
    "\n",
    "# AUC (Area Under the Curve)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# Plotting the ROC Curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_lr, tpr_lr, color='blue', label=f'Logistic Regression (AUC = {roc_auc_lr:.2f})')\n",
    "plt.plot(fpr_rf, tpr_rf, color='green', label=f'Random Forest (AUC = {roc_auc_rf:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Supondo que você já tenha os valores reais e as previsões dos modelos\n",
    "# y_true = valores reais\n",
    "# y_pred_logistic = previsões do modelo de Regressão Logística\n",
    "# y_pred_rf = previsões do modelo de Random Forest\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['INDEFERIDO', 'DEFERIDO', 'NÃO DEFINIDO'],\n",
    "                yticklabels=['INDEFERIDO', 'DEFERIDO', 'NÃO DEFINIDO'])\n",
    "    #plt.title(f'Matriz de Confusão - {model_name}', fontsize=14)\n",
    "    plt.ylabel('Valores Reais', fontsize=12)\n",
    "    plt.xlabel('Valores Previstos', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "# Exemplo de uso com Regressão Logística\n",
    "plot_confusion_matrix(y_test, y_pred_logistic, \"Regressão Logística\")\n",
    "\n",
    "# Exemplo de uso com Random Forest\n",
    "plot_confusion_matrix(y_test, y_pred_rf, \"Random Forest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado não supervisionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### De Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_df(df, num_features):\n",
    "\n",
    "  correlation_matrix = df.corr()\n",
    "\n",
    "  average_correlation = correlation_matrix.abs().mean().sort_values()\n",
    "\n",
    "  smallest_average_correlations = average_correlation.head(num_features).index.tolist()\n",
    "\n",
    "  return df[smallest_average_correlations]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_df(df, num_components):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    return pd.DataFrame(pca.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nn_accuracy(df, labels):\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.metrics import accuracy_score\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.3, random_state=42)\n",
    "  knn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "  knn.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = knn.predict(X_test)\n",
    "\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_representation(df1, df2, labels):\n",
    "  accuracy1 = get_k_nn_accuracy(df1, labels)\n",
    "  accuracy2 = get_k_nn_accuracy(df2, labels)\n",
    "\n",
    "  print(f'1: {accuracy1} x 2: {accuracy2}')\n",
    "\n",
    "  return df1 if accuracy1 > accuracy2 else df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf = data_tfidf.drop(['advogado_2', 'requerente_3', 'requerente_4', \n",
    "                            'requerente_5', 'requerente_6', 'requerente_7', \n",
    "                            'impugnado_2', 'impugnado', 'fiscal_de_lei_nome',\n",
    "                            'formal_request','free_judicial', 'judicial_secrecy', 'id'] , axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1 = get_k_nn_accuracy(data_tfidf, labels)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecionando de atributos pela correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset_corr_3 = get_correlation_df(data_tfidf, 3)\n",
    "reduced_dataset_corr_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset_corr_9 = get_correlation_df(data_tfidf, 9)\n",
    "reduced_dataset_corr_9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df_corr = get_best_representation(reduced_dataset_corr_3, reduced_dataset_corr_9, labels)\n",
    "selected_df_corr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Redução de dimensionalidade pelo PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca_90_cov = get_pca_df(data_tfidf, 0.9)\n",
    "dataset_pca_90_cov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca_3_cps = get_pca_df(data_tfidf, 3)\n",
    "dataset_pca_3_cps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df_pca = get_best_representation(dataset_pca_90_cov, dataset_pca_3_cps, labels)\n",
    "selected_df_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_values(df, labels, model_labels):\n",
    "    from sklearn.metrics import davies_bouldin_score, silhouette_score, adjusted_rand_score\n",
    "\n",
    "    indice_db = davies_bouldin_score(df, model_labels)\n",
    "    indice_sil = silhouette_score(df, model_labels, metric='euclidean')\n",
    "    indice_cr = adjusted_rand_score(labels, model_labels)\n",
    "\n",
    "    return indice_db, indice_sil, indice_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_labels(df, num_clusters):\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    km = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "    \n",
    "    km.fit(df)\n",
    "\n",
    "    return km.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hierarquico_labels(df, num_clusters, linkage):\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "    hiera_aglo = AgglomerativeClustering(n_clusters=num_clusters, metric='euclidean', linkage=linkage)\n",
    "    \n",
    "    hiera_aglo.fit(df)\n",
    "\n",
    "    return hiera_aglo.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_em_labels(df, num_components, cov_type):\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    from sklearn.metrics import davies_bouldin_score, silhouette_score, adjusted_rand_score\n",
    "\n",
    "    gmm = GaussianMixture(n_components=num_components, covariance_type=cov_type)\n",
    "\n",
    "    gmm.fit(df)\n",
    "\n",
    "    return gmm.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbscan_labels(df, eps_value, minimum_samples):\n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    dbscan = DBSCAN(eps=eps_value, min_samples=minimum_samples)\n",
    "    \n",
    "    dbscan.fit(df)\n",
    "\n",
    "    return dbscan.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_labels(df, **kwargs):\n",
    "    import pandas as pd\n",
    "\n",
    "    labels_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        km_labels = get_kmeans_labels(df, index)\n",
    "        gmm_labels = get_hierarquico_labels(df, index, kwargs.get('linkage'))\n",
    "        em_labels = get_em_labels(df, index, kwargs.get('cov_type'))\n",
    "        dbscan_labels = get_dbscan_labels(df, kwargs.get('eps_value'), index)\n",
    "\n",
    "        labels_values = {'Grupos': index, 'Kmeans': km_labels, 'Hierarquico': gmm_labels, 'EM': em_labels, 'DBSCAN': dbscan_labels}\n",
    "\n",
    "        labels_data.append(labels_values)\n",
    "        \n",
    "    df_labels = pd.DataFrame(labels_data)\n",
    "    df_labels.index = df_labels.index + 2\n",
    "\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_indices(df, labels, models_labels, is_corr):\n",
    "    import pandas as pd\n",
    "\n",
    "    indices_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        db_value_km, sil_value_km, cr_value_km = get_indices_values(df, labels, models_labels.loc[index, 'Kmeans'])\n",
    "        db_value_hiera, sil_value_hiera, cr_value_hiera = get_indices_values(df, labels, models_labels.loc[index, 'Hierarquico'])\n",
    "        db_value_em, sil_value_em, cr_value_em = get_indices_values(df, labels, models_labels.loc[index, 'EM'])\n",
    "        if not is_corr:\n",
    "            db_value_dbscan, sil_value_dbscan, cr_value_dbscan = get_indices_values(df, labels, models_labels.loc[index, 'DBSCAN'])\n",
    "\n",
    "        indices_values = {\n",
    "                          'Grupos': index, \n",
    "                          'Kmeans': {'DB': db_value_km, 'SIL': sil_value_km, 'CR': cr_value_km}, \n",
    "                          'Hierarquico': {'DB': db_value_hiera, 'SIL': sil_value_hiera, 'CR': cr_value_hiera}, \n",
    "                          'EM': {'DB': db_value_em, 'SIL': sil_value_em, 'CR': cr_value_em}, \n",
    "                         }       \n",
    "        \n",
    "        if not is_corr:\n",
    "                indices_values.update({'DBSCAN': {'DB': db_value_dbscan, 'SIL': sil_value_dbscan, 'CR': cr_value_dbscan}})\n",
    "\n",
    "        indices_data.append(indices_values)\n",
    "        \n",
    "    df_indices = pd.DataFrame(indices_data)\n",
    "    df_indices.index = df_indices.index + 2\n",
    "\n",
    "    return df_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_indices(df_orig, df_corr, df_pca, cluster_type):\n",
    "    import pandas as pd\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    indices_list = ['DB', 'SIL', 'CR']\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=3, subplot_titles=('Índice - Davies-Bouldin', 'Índice - Silhouette', 'Índice - Adjusted Rand Score'))\n",
    "    \n",
    "    for index, indice in enumerate(indices_list, 1):\n",
    "      fig.add_trace(go.Scatter(x=df_orig['Grupos'], y=df_orig[cluster_type].apply(lambda x: x[indice]), name='Base original'), row=1, col=index)\n",
    "      if cluster_type != 'DBSCAN':\n",
    "        fig.add_trace(go.Scatter(x=df_corr['Grupos'], y=df_corr[cluster_type].apply(lambda x: x[indice]), name='Correlação'), row=1, col=index)\n",
    "      fig.add_trace(go.Scatter(x=df_pca['Grupos'], y=df_pca[cluster_type].apply(lambda x: x[indice]), name='PCA'), row=1, col=index)\n",
    "\n",
    "    fig.update_layout(title=f'Gráfico de {cluster_type.upper()}', showlegend=True, boxmode='group')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geração de gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_models_labels = get_models_labels(data_tfidf, linkage='ward', cov_type='full', eps_value=.1)\n",
    "pca_models_labels = get_models_labels(selected_df_pca, linkage='ward', cov_type='full', eps_value=.1)\n",
    "corr_models_labels = get_models_labels(selected_df_corr, linkage='ward', cov_type='full', eps_value=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cluster_indices = get_cluster_indices(data_tfidf, labels, original_models_labels, False)\n",
    "pca_cluster_indices = get_cluster_indices(selected_df_pca, labels, pca_models_labels, False)\n",
    "corr_cluster_indices = get_cluster_indices(selected_df_corr, labels, corr_models_labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade jupyter notebook jupyterlab plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices, corr_cluster_indices, pca_cluster_indices, 'Kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices, corr_cluster_indices, pca_cluster_indices, 'Hierarquico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices, corr_cluster_indices, pca_cluster_indices, 'EM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_indices(original_cluster_indices, corr_cluster_indices, pca_cluster_indices, 'DBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comitê de Agrupamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_binary_matrix(clabels):\n",
    "    from scipy import sparse\n",
    "\n",
    "    data_len = len(clabels) \n",
    "\n",
    "    matrix = np.zeros((data_len, data_len))\n",
    "    \n",
    "    for index in range(data_len):\n",
    "        matrix[index,:] = clabels == clabels[index]\n",
    "\n",
    "    return matrix   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(models_labels):\n",
    "    n_runs, n_data = models_labels.shape[0], models_labels.shape[1]\n",
    "\n",
    "    sim_matrix = np.zeros( (n_data, n_data) )\n",
    "\n",
    "    for index in range(n_runs):\n",
    "        sim_matrix += build_binary_matrix( models_labels[index,:] )\n",
    "\n",
    "    sim_matrix = sim_matrix / n_runs\n",
    "\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_indices(df, final_labels, labels):\n",
    "    from sklearn.metrics import davies_bouldin_score, silhouette_score, adjusted_rand_score\n",
    "\n",
    "    indice_db = davies_bouldin_score(df, final_labels)\n",
    "    indice_sil = silhouette_score(df, final_labels, metric='euclidean')\n",
    "    indice_cr = adjusted_rand_score(labels, final_labels)\n",
    " \n",
    "    return indice_db, indice_sil, indice_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_labels_en(df: pd.DataFrame, num_clusters):\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    km_model = KMeans(n_clusters=num_clusters, n_init=4, random_state=214)\n",
    "    km_model.fit(df)\n",
    "\n",
    "    return km_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hierarquico_labels_en(df: pd.DataFrame, num_clusters):\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "    agglo_model = AgglomerativeClustering(n_clusters=num_clusters)\n",
    "    agglo_model.fit(df)\n",
    "\n",
    "    return agglo_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_em_labels_en(df: pd.DataFrame, num_components):\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    \n",
    "    gmm_model = GaussianMixture(n_components=num_components, random_state=214)\n",
    "\n",
    "    gmm_model.fit(df)\n",
    "    labels = gmm_model.predict(df)\n",
    "\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbscan_labels_en(df, eps, min_samples):\n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    dbscan_models = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "\n",
    "    dbscan_models.fit(df)\n",
    "     \n",
    "    return dbscan_models.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_matrix_en(models_labels: np.ndarray):\n",
    "    \n",
    "    return build_similarity_matrix(models_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_labels_en(sim_matrix, num_clusters):\n",
    "    from sklearn.cluster import SpectralClustering\n",
    "\n",
    "    spec_clt = SpectralClustering(n_clusters=num_clusters, affinity='precomputed',\n",
    "                                n_init=5, random_state=214)\n",
    "\n",
    "    final_labels = spec_clt.fit_predict(sim_matrix)\n",
    "\n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_df(df: pd.DataFrame, labels: np.ndarray, **kwargs) -> pd.DataFrame:\n",
    "    import pandas as pd\n",
    "\n",
    "    indices_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        db_df, sil_df, cr_df = {}, {}, {}\n",
    "        \n",
    "        kmeans_labels = get_kmeans_labels_en(df, index)\n",
    "        hierarquico_labels = get_hierarquico_labels_en(df, index)\n",
    "        em_labels = get_em_labels_en(df, index)\n",
    "        dbscan_labels = get_dbscan_labels_en(df, .1, index)\n",
    "\n",
    "        models_labels = np.array([kmeans_labels, hierarquico_labels, em_labels, dbscan_labels])\n",
    "\n",
    "        sim_matrix = get_similarity_matrix_en(models_labels)\n",
    "\n",
    "        final_labels = get_final_labels_en(sim_matrix, index)\n",
    "\n",
    "        db_value, sil_value, cr_value = get_ensemble_indices(df, final_labels, labels)\n",
    "\n",
    "        indice_values = {'Grupos': index, 'DB': db_value, 'Silhouette': sil_value, 'CR': cr_value, 'Labels': final_labels}\n",
    "        indices_data.append(indice_values)\n",
    "        \n",
    "\n",
    "    indices_ensemble_df = pd.DataFrame(indices_data)\n",
    "    indices_ensemble_df.index = indices_ensemble_df.index + 2\n",
    "\n",
    "    return indices_ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ensemble_indices(en_df_original: pd.DataFrame, en_df_corr: pd.DataFrame, en_df_pca: pd.DataFrame, indice_name: str) -> None:\n",
    "    import pandas as pd\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    indice_data = []\n",
    "\n",
    "    for index in range(2, 21):\n",
    "        indice_values = {'Grupos': index + 2, \n",
    "                         'Original': en_df_original.loc[index, indice_name], \n",
    "                         'Correlação': en_df_corr.loc[index, indice_name], \n",
    "                         'PCA': en_df_pca.loc[index, indice_name]\n",
    "                        }\n",
    "        indice_data.append(indice_values)\n",
    "\n",
    "    df = pd.DataFrame(indice_data)\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1, subplot_titles=(f'Índice - {indice_name}'))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df['Grupos'], y=df['Original'], name='Base original'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df['Grupos'], y=df['Correlação'], name='Correlação'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df['Grupos'], y=df['PCA'], name='PCA'), row=1, col=1)\n",
    "\n",
    "    fig.update_layout(title=f'Gráfico de comitê de agrupamento - Índice {indice_name}', showlegend=True, boxmode='group')\n",
    "    fig.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_df_original = get_ensemble_df(data_tfidf, labels)\n",
    "ensemble_df_corr = get_ensemble_df(selected_df_corr, labels)\n",
    "ensemble_df_pca = get_ensemble_df(selected_df_pca, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble_indices(ensemble_df_original, ensemble_df_corr, ensemble_df_pca, 'DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble_indices(ensemble_df_original, ensemble_df_corr, ensemble_df_pca, 'Silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble_indices(ensemble_df_original, ensemble_df_corr, ensemble_df_pca, 'CR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste Estatístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cr_df() -> pd.DataFrame:\n",
    "    cr_data = pd.DataFrame(columns=[\n",
    "        'kmeans', 'hierarquico', 'em', 'dbscan', 'ensemble'\n",
    "    ], index=range(2, 21))\n",
    "\n",
    "    return cr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cr_values(df, ensemble_df):\n",
    "    result_df = get_cr_df()\n",
    "\n",
    "    km_cr_values = df['Kmeans'].apply(lambda x: x['CR'])\n",
    "    ag_cr_values = df['Hierarquico'].apply(lambda x: x['CR'])\n",
    "    em_cr_values = df['EM'].apply(lambda x: x['CR'])\n",
    "    dbscan_cr_values = df['DBSCAN'].apply(lambda x: x['CR'])\n",
    "\n",
    "    for num_cluster in range(2, 21):\n",
    "        result_df.loc[num_cluster] = [ \n",
    "                                        km_cr_values.loc[num_cluster],\n",
    "                                        ag_cr_values.loc[num_cluster],\n",
    "                                        em_cr_values.loc[num_cluster],\n",
    "                                        dbscan_cr_values.loc[num_cluster],\n",
    "                                        ensemble_df.loc[num_cluster, 'CR']\n",
    "                                     ]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cr_values_corr(df, ensemble_df):\n",
    "    result_df = get_cr_df()\n",
    "    result_df = result_df.drop('dbscan', axis=1)\n",
    "\n",
    "    km_cr_values = df['Kmeans'].apply(lambda x: x['CR'])\n",
    "    ag_cr_values = df['Hierarquico'].apply(lambda x: x['CR'])\n",
    "    em_cr_values = df['EM'].apply(lambda x: x['CR'])\n",
    "\n",
    "    for num_cluster in range(2, 21):\n",
    "        result_df.loc[num_cluster] = [ \n",
    "                                        km_cr_values.loc[num_cluster],\n",
    "                                        ag_cr_values.loc[num_cluster],\n",
    "                                        em_cr_values.loc[num_cluster],\n",
    "                                        ensemble_df.loc[num_cluster, 'CR']\n",
    "                                     ]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_friedman_result(df):\n",
    "    from scipy.stats import friedmanchisquare\n",
    "\n",
    "    friedman_chi2, friedman_p_value = friedmanchisquare(*[df[col] for col in df.columns])\n",
    "    print(\"Teste de Friedman\")\n",
    "    print(f\"p-valor: {friedman_p_value:.4f}\")\n",
    "    print(f\"qui-quadrado: {friedman_chi2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nemenyi_result(df):\n",
    "    from scikit_posthocs import posthoc_nemenyi_friedman\n",
    "\n",
    "    nemenyi_results = posthoc_nemenyi_friedman(df)\n",
    "    print(\"Teste Nemenyi (pós-hoc):\")\n",
    "    print(nemenyi_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nemenyi_result(df, title):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scikit_posthocs import posthoc_nemenyi_friedman\n",
    "    \n",
    "    nemenyi_results = posthoc_nemenyi_friedman(df)\n",
    "    \n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.heatmap(nemenyi_results, annot=True, cmap='coolwarm', fmt=\".4f\", cbar=True,\n",
    "                linewidths=0.5, linecolor='black', vmin=0, vmax=1)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_original = fill_cr_values(original_cluster_indices, ensemble_df_original)\n",
    "cr_pca = fill_cr_values(pca_cluster_indices, ensemble_df_pca)\n",
    "cr_corr = fill_cr_values_corr(corr_cluster_indices, ensemble_df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original\")\n",
    "print_friedman_result(cr_original)\n",
    "print(\"Corr\")\n",
    "print_friedman_result(cr_corr)\n",
    "print(\"PCA\")\n",
    "print_friedman_result(cr_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original\")\n",
    "print_nemenyi_result(cr_original)\n",
    "print(\"Corr\")\n",
    "print_nemenyi_result(cr_corr)\n",
    "print(\"PCA\")\n",
    "print_nemenyi_result(cr_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nemenyi_result(cr_original, \"Teste Nemenyi (pós-hoc) - Original\")\n",
    "plot_nemenyi_result(cr_corr, \"Teste Nemenyi (pós-hoc) - Correlação\")\n",
    "plot_nemenyi_result(cr_pca, \"Teste Nemenyi (pós-hoc) - PCA\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
