{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajxqeWPm-QWE"
   },
   "source": [
    "# Instalar dependências necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKWsHLsz-O_k"
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pdf_folder = '../data'\n",
    "\n",
    "pdf_files_path = []\n",
    "for root, dirs, files in os.walk(pdf_folder):\n",
    "  for file in files:\n",
    "    if file.endswith('.pdf'):\n",
    "      pdf_files_path.append(os.path.join(root, file))\n",
    "\n",
    "raw_texts = []\n",
    "\n",
    "for pdf_file_path in pdf_files_path:\n",
    "  whole_text = ''\n",
    "\n",
    "  with pdfplumber.open(pdf_file_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "      text = page.extract_text()\n",
    "      whole_text += f\"{text}\\n\"\n",
    "\n",
    "  raw_texts.append(whole_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrair o texto não estruturado do PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYhpBB4oDlA_"
   },
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(data={'raw': raw_texts})\n",
    "\n",
    "row_count = dataframe.count()\n",
    "columns = dataframe.columns\n",
    "print(f\"Row count: {row_count}\")\n",
    "print(f\"Columns: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_based_on_appearance_in_text(text_to_extract: str, text: str, type: str = 'after'):\n",
    "  \"\"\"\n",
    "  Extracts the text after the appearance of a specific text in a given string.\n",
    "\n",
    "  Parameters:\n",
    "    text_to_extract (str): The text to extract.\n",
    "    text (str): The input string.\n",
    "    type (str): The type of extraction. It can be either \"before\" or \"after\".\n",
    "\n",
    "  Returns:\n",
    "    str: The extracted text.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If the type is neither \"before\" nor \"after\".\n",
    "  \"\"\"\n",
    "\n",
    "  import re\n",
    "\n",
    "  if type == 'before':\n",
    "    search = re.search(rf'.*(?<={text_to_extract})', text, re.DOTALL)\n",
    "  elif type == 'after':\n",
    "    search = re.search(rf'(?<={text_to_extract}).*', text)\n",
    "  else:\n",
    "    raise ValueError('type must be either \"before\" or \"after\"')\n",
    "\n",
    "  extracted_text = search.group().strip() if search else None\n",
    "\n",
    "  return extracted_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all essential data from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "def extract_needed_information_from_pdf_text(text: str):\n",
    "  \"\"\"\n",
    "  Extracts the needed information from a given PDF text.\n",
    "\n",
    "  Parameters:\n",
    "    text (str): The input text.\n",
    "\n",
    "  Returns:\n",
    "    dict: The extracted information.\n",
    "  \"\"\"\n",
    "\n",
    "  # Remove redundant texts that are not useful for the analysis\n",
    "  text = re.sub(r'\\bTribunal Regional Eleitoral do Rio Grande do Norte\\n\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\bPJe - Processo Judicial Eletrônico\\n\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\bN úmero: \\b', '', text, count=1)\n",
    "\n",
    "  # Extracting the date of process\n",
    "  date_pattern = r'\\d{2}/\\d{2}/\\d{4}'\n",
    "  date_match = re.search(date_pattern, text)\n",
    "  date = date_match.group() if date_match else None \n",
    "  print(date)\n",
    "\n",
    "  text = re.sub(date_pattern, '\\n', text, count=1)\n",
    "\n",
    "  # Extracting the legal action number\n",
    "  legal_action_number_pattern = r'\\b\\d{7}-\\d{2}.\\d{4}.\\d{1}.\\d{2}.\\d{4}\\b' \n",
    "  legal_action_number_match = re.search(legal_action_number_pattern, text)\n",
    "  legal_action_number = legal_action_number_match.group() if legal_action_number_match else None\n",
    "  text = re.sub(legal_action_number_pattern, '\\n', text, count=1)\n",
    "  print(legal_action_number)\n",
    "\n",
    "\n",
    "  # Extracting the data of raw text\n",
    "  search = 'Classe:'\n",
    "  legal_class = extract_text_based_on_appearance_in_text(search, text)\n",
    "  print(legal_class)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {legal_class}\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Órgão julgador:'\n",
    "  tribunal = extract_text_based_on_appearance_in_text(search, text)\n",
    "  print(tribunal)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {tribunal}\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Última distribuição :'\n",
    "  last_distribution = extract_text_based_on_appearance_in_text('Última distribuição :', text)\n",
    "  print(last_distribution)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {last_distribution}\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Processo referência:'\n",
    "  reference_legal_action = extract_text_based_on_appearance_in_text('Processo referência:', text)\n",
    "  print(reference_legal_action)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {reference_legal_action}\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Assuntos:'\n",
    "  matters = extract_text_based_on_appearance_in_text('Assuntos:', text)\n",
    "  print(matters)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {matters}\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Cargo -'\n",
    "  position = extract_text_based_on_appearance_in_text('Cargo -', text)\n",
    "  print(position)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {position}\\n\\b', '', text, count=1)\n",
    "\n",
    "  legal_action_goal_string = 'Objeto do processo: '\n",
    "  judicial_secrecy = 'Segredo de Justiça?'\n",
    "  extracted_text = re.search(f'{legal_action_goal_string}(.*?){judicial_secrecy}', text, re.DOTALL)\n",
    "  legal_action_goal = extracted_text.group(1).strip() if extracted_text else None\n",
    "  print(legal_action_goal)\n",
    "\n",
    "  text = re.sub(rf'\\b{legal_action_goal_string}\\b', '', text.strip(), count=1)\n",
    "  legal_action_goal = legal_action_goal.replace('\\n', ' ').strip()\n",
    "\n",
    "  legal_action_goal_splitted = legal_action_goal.split(' ')\n",
    "\n",
    "  for word in legal_action_goal_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "\n",
    "  text = text.strip()\n",
    "\n",
    "  search = 'Segredo de Justiça\\?'\n",
    "  judicial_secrecy = extract_text_based_on_appearance_in_text('Segredo de Justiça\\?', text)\n",
    "  print(judicial_secrecy)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {judicial_secrecy}\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Justiça gratuita\\?'\n",
    "  free_judicial = extract_text_based_on_appearance_in_text('Justiça gratuita\\?', text)\n",
    "  print(free_judicial)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {free_judicial}\\b', '', text, count=1)\n",
    "\n",
    "  search = 'Pedido de liminar ou antecipação de tutela\\?'\n",
    "  formal_request = extract_text_based_on_appearance_in_text('Pedido de liminar ou antecipação de tutela\\?', text)\n",
    "  print(formal_request)\n",
    "\n",
    "  text = re.sub(rf'\\b{search} {formal_request}\\b', '', text, count=1)\n",
    "\n",
    "  text = re.sub(r'\\bPartes Advogados\\n\\b', '', text, count=1)\n",
    "\n",
    "  search = r'\\(REQUERENTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' '))\n",
    "  requerente = match.group(1).strip() if match else None\n",
    "  print(requerente)\n",
    "\n",
    "  text = re.sub(r'\\b(REQUERENTE)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{requerente}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  search = r'\\(ADVOGADO\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' '))\n",
    "  advogado = match.group(1).strip() if match else None\n",
    "  print(advogado)\n",
    "\n",
    "  text = re.sub(r'\\b(ADVOGADO)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{advogado}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  # print(text)\n",
    "  search = r'\\(REQUERENTE\\)'\n",
    "  match = re.search(rf'(.+?)\\s+{search}', text.replace('\\n', ' ').strip())\n",
    "  requerente_2 = match.group(1).strip() if match else None\n",
    "  print(requerente_2)\n",
    "  \n",
    "  requerente2_splitted = requerente_2.split(' ') if requerente_2 != None else []\n",
    "  for word in requerente2_splitted:\n",
    "    word = word.replace('(', r'\\(').replace(')', r'\\)')\n",
    "    text = re.sub(rf'{word}\\n?', '', text, count=1)\n",
    "  text = re.sub(r'\\b(REQUERENTE)\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{requerente_2}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "\n",
    "  outros_participantes_search = 'Outros participantes'\n",
    "  fiscal_de_lei_search = r'\\(FISCAL DA LEI\\)'\n",
    "  extracted_text = re.search(f'{outros_participantes_search}(.*?){fiscal_de_lei_search}', text, re.DOTALL)\n",
    "  fiscal_de_lei_nome = extracted_text.group(1).strip().replace('\\n', ' ') if extracted_text else None\n",
    "  print(fiscal_de_lei_nome)\n",
    "\n",
    "  text = re.sub(rf'\\b{outros_participantes_search}\\n\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\bFISCAL DA LEI\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\(\\)', '', text, count=1)\n",
    "  text = re.sub(r'\\bPROMOTOR ELEITORAL DO ESTADO DO RIO GRANDE DO\\nNORTE\\b', '', text, count=1)\n",
    "\n",
    "  text = re.sub(r'\\bDocumentos\\b', '', text, count=1)\n",
    "\n",
    "  # print('text', text)\n",
    "\n",
    "  text_treated_for_index = text.strip().replace('\\n', ' ').split(' ')\n",
    "\n",
    "  id = text_treated_for_index[6]\n",
    "  print(id)\n",
    "\n",
    "  data_da_assinatura = text_treated_for_index[7]\n",
    "  print(data_da_assinatura)\n",
    "\n",
    "  hora_da_assinatura = text_treated_for_index[10]\n",
    "  print(hora_da_assinatura)\n",
    "\n",
    "  data_hora_da_assinatura = f'{data_da_assinatura} {hora_da_assinatura}'\n",
    "  data_hora_da_assinatura_timestamp = datetime.datetime.strptime(data_hora_da_assinatura, '%d/%m/%Y %H:%M').isoformat()\n",
    "  print(data_hora_da_assinatura_timestamp)\n",
    "\n",
    "  tipo = text_treated_for_index[9]\n",
    "  print(tipo)\n",
    "\n",
    "  text = re.sub(r'\\bId. Data da Documento Tipo Assinatura\\b', '', text.replace('\\n', ' '), count=1)\n",
    "  text = re.sub(rf'\\b{id}\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{data_da_assinatura}\\b', '', text, count=1)\n",
    "  text = re.sub(rf'\\b{hora_da_assinatura}\\b', '', text, count=1)\n",
    "  text = re.sub(r'\\bSentença\\b', '', text, count=2)\n",
    "\n",
    "  documento = text\n",
    "\n",
    "  resultado = 'NÃO DEFINIDO'\n",
    "  \n",
    "  indeferimento_word_appearance = documento.lower().find('indefiro')\n",
    "\n",
    "  if indeferimento_word_appearance != -1:\n",
    "    resultado = 'INDEFERIDO'\n",
    "  \n",
    "  if documento.lower().find('defiro') != -1:\n",
    "    resultado = 'DEFERIDO'\n",
    "\n",
    "  print(resultado)\n",
    "\n",
    "  data = {\n",
    "    'advogado': advogado,\n",
    "    'data_hora_da_assinatura_timestamp': data_hora_da_assinatura_timestamp,\n",
    "    'documento': documento,\n",
    "    'fiscal_de_lei_nome': fiscal_de_lei_nome,\n",
    "    'formal_request': formal_request,\n",
    "    'free_judicial': free_judicial,\n",
    "    'id': id,\n",
    "    'judicial_secrecy': judicial_secrecy,\n",
    "    'last_distribution': last_distribution,\n",
    "    'legal_action_goal': legal_action_goal,\n",
    "    'legal_action_number': legal_action_number,\n",
    "    'legal_class': legal_class,\n",
    "    'matters': matters,\n",
    "    'position': position,\n",
    "    'reference_legal_action': reference_legal_action,\n",
    "    'requerente': requerente,\n",
    "    'requerente_2': requerente_2,\n",
    "    'resultado': resultado,\n",
    "  }\n",
    "\n",
    "  return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "pdf_files_path_with_error = []\n",
    "\n",
    "for index, raw_text in enumerate(dataframe['raw']):\n",
    "  # if index != 2:\n",
    "  #   continue\n",
    "  \n",
    "  try:\n",
    "    data = extract_needed_information_from_pdf_text(raw_text)\n",
    "    new_row = pd.DataFrame([data])\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "  except ValueError:\n",
    "    pdf_files_path_with_error.append(pdf_files_path[index])\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_files_path_with_error)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
